{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = 'data/'\n",
    "file_names = [\n",
    "    'Batch_corrected_Expression_Public_24Q4_subsetted.csv',\n",
    "    'Damaging_Mutations_subsetted.csv', \n",
    "    'Harmonized_RPPA_CCLE_subsetted.csv',\n",
    "    'Hotspot_Mutations_subsetted.csv', \n",
    "    'IC50_AUC_merged.csv', \n",
    "    'Metabolomics_subsetted.csv',\n",
    "    'miRNA_Expression_subsetted.csv',\n",
    "    'Omics_Absolute_CN_Gene_Public_24Q4_subsetted.csv'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19736\\2248293798.py:35: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  absolute_copy_number = pd.read_csv(f'{data_directory}{file_names[7]}')\n"
     ]
    }
   ],
   "source": [
    "# Read and modify batch_corrected_expression\n",
    "batch_corrected_expression = pd.read_csv(f'{data_directory}{file_names[0]}')\n",
    "batch_corrected_expression = batch_corrected_expression.rename(columns={batch_corrected_expression.columns[0]: \"CellLineID\"})\n",
    "batch_corrected_expression.columns = ['CellLineID'] + [f\"1_{col}\" for col in batch_corrected_expression.columns[1:]]\n",
    "\n",
    "# Read and modify damaging_mutations\n",
    "damaging_mutations = pd.read_csv(f'{data_directory}{file_names[1]}')\n",
    "damaging_mutations = damaging_mutations.rename(columns={damaging_mutations.columns[0]: \"CellLineID\"})\n",
    "damaging_mutations.columns = ['CellLineID'] + [f\"2_{col}\" for col in damaging_mutations.columns[1:]]\n",
    "\n",
    "# Read and modify harmonized_RPPA\n",
    "harmonized_RPPA = pd.read_csv(f'{data_directory}{file_names[2]}')\n",
    "harmonized_RPPA = harmonized_RPPA.rename(columns={harmonized_RPPA.columns[0]: \"CellLineID\"})\n",
    "harmonized_RPPA.columns = ['CellLineID'] + [f\"3_{col}\" for col in harmonized_RPPA.columns[1:]]\n",
    "\n",
    "# Read and modify hotspot_mutations\n",
    "hotspot_mutations = pd.read_csv(f'{data_directory}{file_names[3]}')\n",
    "hotspot_mutations = hotspot_mutations.rename(columns={hotspot_mutations.columns[0]: \"CellLineID\"})\n",
    "hotspot_mutations.columns = ['CellLineID'] + [f\"4_{col}\" for col in hotspot_mutations.columns[1:]]\n",
    "\n",
    "IC50_AUC = pd.read_csv(f'{data_directory}{file_names[4]}')\n",
    "IC50_AUC = IC50_AUC.rename(columns={IC50_AUC.columns[0]: \"CellLineID\"})\n",
    "\n",
    "# Read and modify metabolomics\n",
    "metabolomics = pd.read_csv(f'{data_directory}{file_names[5]}')\n",
    "metabolomics = metabolomics.rename(columns={metabolomics.columns[0]: \"CellLineID\"})\n",
    "metabolomics.columns = ['CellLineID'] + [f\"5_{col}\" for col in metabolomics.columns[1:]]\n",
    "\n",
    "# Read and modify miRNA_expression\n",
    "miRNA_expression = pd.read_csv(f'{data_directory}{file_names[6]}')\n",
    "miRNA_expression = miRNA_expression.rename(columns={miRNA_expression.columns[0]: \"CellLineID\"})\n",
    "miRNA_expression.columns = ['CellLineID'] + [f\"6_{col}\" for col in miRNA_expression.columns[1:]]\n",
    "\n",
    "# Read and modify absolute_copy_number\n",
    "absolute_copy_number = pd.read_csv(f'{data_directory}{file_names[7]}')\n",
    "absolute_copy_number = absolute_copy_number.rename(columns={absolute_copy_number.columns[0]: \"CellLineID\"})\n",
    "absolute_copy_number = absolute_copy_number.drop(columns=[\"cell_line_display_name\", \"lineage_1\", \"lineage_2\", \"lineage_3\", \"lineage_6\", \"lineage_4\"])\n",
    "absolute_copy_number.columns = ['CellLineID'] + [f\"7_{col}\" for col in absolute_copy_number.columns[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellLineID</th>\n",
       "      <th>1_NEMP2</th>\n",
       "      <th>1_SPDYE11</th>\n",
       "      <th>1_MED6</th>\n",
       "      <th>1_SPATA1</th>\n",
       "      <th>1_HMG20B</th>\n",
       "      <th>1_PITRM1</th>\n",
       "      <th>1_TCIRG1</th>\n",
       "      <th>1_CDKN2B</th>\n",
       "      <th>1_MKRN2OS</th>\n",
       "      <th>...</th>\n",
       "      <th>1_XYLB</th>\n",
       "      <th>1_CDC25A</th>\n",
       "      <th>1_NR1H4</th>\n",
       "      <th>1_NUP153</th>\n",
       "      <th>1_SUPT7L</th>\n",
       "      <th>1_GFPT2</th>\n",
       "      <th>1_USP15</th>\n",
       "      <th>1_IQSEC1</th>\n",
       "      <th>1_FGFBP1</th>\n",
       "      <th>1_FGF19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000873</td>\n",
       "      <td>2.281262</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>4.913394</td>\n",
       "      <td>0.592549</td>\n",
       "      <td>4.933815</td>\n",
       "      <td>5.068384</td>\n",
       "      <td>4.910413</td>\n",
       "      <td>0.996458</td>\n",
       "      <td>0.035011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.522375</td>\n",
       "      <td>2.734131</td>\n",
       "      <td>0.036676</td>\n",
       "      <td>4.489500</td>\n",
       "      <td>4.126495</td>\n",
       "      <td>2.933520</td>\n",
       "      <td>4.679719</td>\n",
       "      <td>2.658149</td>\n",
       "      <td>6.949334</td>\n",
       "      <td>0.067254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000860</td>\n",
       "      <td>2.397921</td>\n",
       "      <td>-0.007359</td>\n",
       "      <td>6.064227</td>\n",
       "      <td>0.790612</td>\n",
       "      <td>5.526024</td>\n",
       "      <td>5.495815</td>\n",
       "      <td>5.223437</td>\n",
       "      <td>3.722068</td>\n",
       "      <td>0.486790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.401933</td>\n",
       "      <td>4.026986</td>\n",
       "      <td>0.102299</td>\n",
       "      <td>4.812712</td>\n",
       "      <td>4.754488</td>\n",
       "      <td>1.668809</td>\n",
       "      <td>5.260394</td>\n",
       "      <td>2.678779</td>\n",
       "      <td>5.844726</td>\n",
       "      <td>0.406430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000439</td>\n",
       "      <td>1.961548</td>\n",
       "      <td>0.139871</td>\n",
       "      <td>4.366399</td>\n",
       "      <td>0.574739</td>\n",
       "      <td>5.879936</td>\n",
       "      <td>5.027458</td>\n",
       "      <td>6.596313</td>\n",
       "      <td>-0.026794</td>\n",
       "      <td>0.283322</td>\n",
       "      <td>...</td>\n",
       "      <td>1.871678</td>\n",
       "      <td>4.355534</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>4.359530</td>\n",
       "      <td>4.027693</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>4.765310</td>\n",
       "      <td>3.460506</td>\n",
       "      <td>-0.096728</td>\n",
       "      <td>0.001493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000318</td>\n",
       "      <td>2.962951</td>\n",
       "      <td>-0.007359</td>\n",
       "      <td>6.028266</td>\n",
       "      <td>0.636129</td>\n",
       "      <td>4.722188</td>\n",
       "      <td>5.235858</td>\n",
       "      <td>5.235896</td>\n",
       "      <td>0.043358</td>\n",
       "      <td>2.200371</td>\n",
       "      <td>...</td>\n",
       "      <td>1.720886</td>\n",
       "      <td>2.895112</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>3.991084</td>\n",
       "      <td>4.657785</td>\n",
       "      <td>1.441628</td>\n",
       "      <td>5.563495</td>\n",
       "      <td>1.228177</td>\n",
       "      <td>7.678403</td>\n",
       "      <td>0.001493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-001142</td>\n",
       "      <td>1.997125</td>\n",
       "      <td>-0.007359</td>\n",
       "      <td>4.781246</td>\n",
       "      <td>1.004993</td>\n",
       "      <td>5.559541</td>\n",
       "      <td>6.614231</td>\n",
       "      <td>6.000796</td>\n",
       "      <td>5.244141</td>\n",
       "      <td>-0.048123</td>\n",
       "      <td>...</td>\n",
       "      <td>1.816077</td>\n",
       "      <td>2.128269</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>4.144621</td>\n",
       "      <td>4.822296</td>\n",
       "      <td>6.326762</td>\n",
       "      <td>5.743718</td>\n",
       "      <td>3.069706</td>\n",
       "      <td>-0.137807</td>\n",
       "      <td>-0.012049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>ACH-001843</td>\n",
       "      <td>2.425672</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>5.064429</td>\n",
       "      <td>1.155729</td>\n",
       "      <td>6.132326</td>\n",
       "      <td>6.435993</td>\n",
       "      <td>6.059272</td>\n",
       "      <td>0.075189</td>\n",
       "      <td>0.294127</td>\n",
       "      <td>...</td>\n",
       "      <td>1.809829</td>\n",
       "      <td>2.525644</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>3.596841</td>\n",
       "      <td>5.268157</td>\n",
       "      <td>4.697931</td>\n",
       "      <td>5.741231</td>\n",
       "      <td>2.436233</td>\n",
       "      <td>0.248119</td>\n",
       "      <td>0.045752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>ACH-002074</td>\n",
       "      <td>2.435179</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>4.795754</td>\n",
       "      <td>0.494388</td>\n",
       "      <td>5.265443</td>\n",
       "      <td>5.683454</td>\n",
       "      <td>1.697058</td>\n",
       "      <td>1.882359</td>\n",
       "      <td>0.230385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.768574</td>\n",
       "      <td>4.710684</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>6.343630</td>\n",
       "      <td>4.363348</td>\n",
       "      <td>1.019808</td>\n",
       "      <td>5.406873</td>\n",
       "      <td>4.043767</td>\n",
       "      <td>1.515018</td>\n",
       "      <td>0.091958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>ACH-001164</td>\n",
       "      <td>1.893673</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>4.460321</td>\n",
       "      <td>0.362453</td>\n",
       "      <td>5.729537</td>\n",
       "      <td>7.230451</td>\n",
       "      <td>4.420567</td>\n",
       "      <td>1.809993</td>\n",
       "      <td>0.190636</td>\n",
       "      <td>...</td>\n",
       "      <td>1.584718</td>\n",
       "      <td>3.526075</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>3.603731</td>\n",
       "      <td>3.929013</td>\n",
       "      <td>1.789794</td>\n",
       "      <td>4.072432</td>\n",
       "      <td>2.397131</td>\n",
       "      <td>0.590804</td>\n",
       "      <td>0.014186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>ACH-003180</td>\n",
       "      <td>2.717188</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>4.991506</td>\n",
       "      <td>0.604765</td>\n",
       "      <td>5.400438</td>\n",
       "      <td>5.396326</td>\n",
       "      <td>4.389461</td>\n",
       "      <td>3.618080</td>\n",
       "      <td>0.190636</td>\n",
       "      <td>...</td>\n",
       "      <td>3.326611</td>\n",
       "      <td>3.303162</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>4.711988</td>\n",
       "      <td>4.557213</td>\n",
       "      <td>3.643244</td>\n",
       "      <td>5.510186</td>\n",
       "      <td>3.488515</td>\n",
       "      <td>0.248119</td>\n",
       "      <td>0.014186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>ACH-001979</td>\n",
       "      <td>2.882293</td>\n",
       "      <td>0.040215</td>\n",
       "      <td>4.678718</td>\n",
       "      <td>0.717236</td>\n",
       "      <td>6.455945</td>\n",
       "      <td>4.943213</td>\n",
       "      <td>2.868661</td>\n",
       "      <td>0.075189</td>\n",
       "      <td>0.190636</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434574</td>\n",
       "      <td>1.630411</td>\n",
       "      <td>0.094110</td>\n",
       "      <td>4.332264</td>\n",
       "      <td>4.005569</td>\n",
       "      <td>1.752036</td>\n",
       "      <td>4.699839</td>\n",
       "      <td>2.234181</td>\n",
       "      <td>0.248119</td>\n",
       "      <td>0.014186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1673 rows × 19099 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CellLineID   1_NEMP2  1_SPDYE11    1_MED6  1_SPATA1  1_HMG20B  1_PITRM1  \\\n",
       "0     ACH-000873  2.281262   0.016496  4.913394  0.592549  4.933815  5.068384   \n",
       "1     ACH-000860  2.397921  -0.007359  6.064227  0.790612  5.526024  5.495815   \n",
       "2     ACH-000439  1.961548   0.139871  4.366399  0.574739  5.879936  5.027458   \n",
       "3     ACH-000318  2.962951  -0.007359  6.028266  0.636129  4.722188  5.235858   \n",
       "4     ACH-001142  1.997125  -0.007359  4.781246  1.004993  5.559541  6.614231   \n",
       "...          ...       ...        ...       ...       ...       ...       ...   \n",
       "1668  ACH-001843  2.425672   0.016474  5.064429  1.155729  6.132326  6.435993   \n",
       "1669  ACH-002074  2.435179   0.016474  4.795754  0.494388  5.265443  5.683454   \n",
       "1670  ACH-001164  1.893673   0.016474  4.460321  0.362453  5.729537  7.230451   \n",
       "1671  ACH-003180  2.717188   0.016474  4.991506  0.604765  5.400438  5.396326   \n",
       "1672  ACH-001979  2.882293   0.040215  4.678718  0.717236  6.455945  4.943213   \n",
       "\n",
       "      1_TCIRG1  1_CDKN2B  1_MKRN2OS  ...    1_XYLB  1_CDC25A   1_NR1H4  \\\n",
       "0     4.910413  0.996458   0.035011  ...  1.522375  2.734131  0.036676   \n",
       "1     5.223437  3.722068   0.486790  ...  2.401933  4.026986  0.102299   \n",
       "2     6.596313 -0.026794   0.283322  ...  1.871678  4.355534 -0.004244   \n",
       "3     5.235896  0.043358   2.200371  ...  1.720886  2.895112 -0.004244   \n",
       "4     6.000796  5.244141  -0.048123  ...  1.816077  2.128269  0.050052   \n",
       "...        ...       ...        ...  ...       ...       ...       ...   \n",
       "1668  6.059272  0.075189   0.294127  ...  1.809829  2.525644  0.004200   \n",
       "1669  1.697058  1.882359   0.230385  ...  1.768574  4.710684  0.004200   \n",
       "1670  4.420567  1.809993   0.190636  ...  1.584718  3.526075  0.019553   \n",
       "1671  4.389461  3.618080   0.190636  ...  3.326611  3.303162  0.004200   \n",
       "1672  2.868661  0.075189   0.190636  ...  1.434574  1.630411  0.094110   \n",
       "\n",
       "      1_NUP153  1_SUPT7L   1_GFPT2   1_USP15  1_IQSEC1  1_FGFBP1   1_FGF19  \n",
       "0     4.489500  4.126495  2.933520  4.679719  2.658149  6.949334  0.067254  \n",
       "1     4.812712  4.754488  1.668809  5.260394  2.678779  5.844726  0.406430  \n",
       "2     4.359530  4.027693  0.044818  4.765310  3.460506 -0.096728  0.001493  \n",
       "3     3.991084  4.657785  1.441628  5.563495  1.228177  7.678403  0.001493  \n",
       "4     4.144621  4.822296  6.326762  5.743718  3.069706 -0.137807 -0.012049  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1668  3.596841  5.268157  4.697931  5.741231  2.436233  0.248119  0.045752  \n",
       "1669  6.343630  4.363348  1.019808  5.406873  4.043767  1.515018  0.091958  \n",
       "1670  3.603731  3.929013  1.789794  4.072432  2.397131  0.590804  0.014186  \n",
       "1671  4.711988  4.557213  3.643244  5.510186  3.488515  0.248119  0.014186  \n",
       "1672  4.332264  4.005569  1.752036  4.699839  2.234181  0.248119  0.014186  \n",
       "\n",
       "[1673 rows x 19099 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_corrected_expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IC50, AUC, SMILES combine\n",
    "smiles = pd.read_csv(\"./data/drugID_name_pubchem_smiles.csv\")\n",
    "# load ChemBERTa tokenizer and model\n",
    "model_name = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# tokenize\n",
    "tokens = tokenizer(smiles[\"smiles\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# embedded tokenized SMILES\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "# CLS token (for now, we will only use CLS token)\n",
    "cls_embeddings = outputs.last_hidden_state[:, 0, :] # (batch_size, hidden_dim)\n",
    "\n",
    "cls_embeddings_np = cls_embeddings.cpu().numpy()\n",
    "\n",
    "smiles[\"CLS\"] = list(cls_embeddings_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = IC50_AUC.melt(\n",
    "    id_vars=[\"CellLineID\"],  # fixed column\n",
    "    var_name=\"metric_drug\",  # column names that will be one single column\n",
    "    value_name=\"value\"       \n",
    ")\n",
    "\n",
    "pattern = r\"(AUC|IC50).*?\\((Sanger GDSC2)\\)\\s+(.*?)\\s+\\(GDSC2:(\\d+)\\)\"\n",
    "melted[[\"Metric\", \"_sanger\", \"DrugName\", \"DrugNumber\"]] = melted[\"metric_drug\"].str.extract(pattern)\n",
    "new_melted = melted[['CellLineID', 'value', 'Metric','DrugNumber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_IC50_AUC = (\n",
    "    new_melted\n",
    "    .pivot(index=[\"CellLineID\", \"DrugNumber\"], \n",
    "           columns=\"Metric\", \n",
    "           values=\"value\")\n",
    "    #.reset_index()\n",
    ")\n",
    "final_IC50_AUC = final_IC50_AUC.dropna(subset=['AUC', 'IC50'], how='all') # drop the row that AUC and IC50 are both NAN\n",
    "final_IC50_AUC.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19736\\4116585332.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat([ic50_data, auc_data])\n"
     ]
    }
   ],
   "source": [
    "final_IC50_AUC.to_csv(\"temp.csv\")\n",
    "IC50_AUC_final = pd.read_csv(\"temp.csv\")\n",
    "df_merged = pd.merge(IC50_AUC_final, smiles, left_on='DrugNumber', right_on='drugID', how='inner')\n",
    "ic50_data = df_merged[['CellLineID', 'DrugNumber', 'smiles', 'CLS', 'IC50']].copy()\n",
    "ic50_data['AUC'] = None # each row will have either AUC or IC50 value. \n",
    "ic50_data = ic50_data.rename(columns={'IC50': 'IC50'})\n",
    "\n",
    "auc_data = df_merged[['CellLineID', 'DrugNumber', 'smiles', 'CLS', 'AUC']].copy()\n",
    "auc_data['IC50'] = None \n",
    "auc_data = auc_data.rename(columns={'AUC': 'AUC'})\n",
    "\n",
    "final_df = pd.concat([ic50_data, auc_data])\n",
    "final_df = final_df.sort_values(by=['CellLineID', 'DrugNumber']).reset_index(drop=True)\n",
    "IC50_AUC_CLS = final_df.dropna(subset=['AUC', 'IC50'], how='all').reset_index(drop=True)\n",
    "\n",
    "IC50_AUC_CLS = IC50_AUC_CLS.drop(columns=[\"DrugNumber\", \"smiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellLineID</th>\n",
       "      <th>1_0</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_2</th>\n",
       "      <th>1_3</th>\n",
       "      <th>1_4</th>\n",
       "      <th>1_5</th>\n",
       "      <th>1_6</th>\n",
       "      <th>1_7</th>\n",
       "      <th>1_8</th>\n",
       "      <th>...</th>\n",
       "      <th>1_490</th>\n",
       "      <th>1_491</th>\n",
       "      <th>1_492</th>\n",
       "      <th>1_493</th>\n",
       "      <th>1_494</th>\n",
       "      <th>1_495</th>\n",
       "      <th>1_496</th>\n",
       "      <th>1_497</th>\n",
       "      <th>1_498</th>\n",
       "      <th>1_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000873</td>\n",
       "      <td>-8.385960</td>\n",
       "      <td>30.391703</td>\n",
       "      <td>-0.819295</td>\n",
       "      <td>44.671643</td>\n",
       "      <td>-26.321860</td>\n",
       "      <td>5.701811</td>\n",
       "      <td>-31.807342</td>\n",
       "      <td>9.832625</td>\n",
       "      <td>0.288482</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.321504</td>\n",
       "      <td>-5.421651</td>\n",
       "      <td>-1.193897</td>\n",
       "      <td>1.788031</td>\n",
       "      <td>1.495077</td>\n",
       "      <td>1.610082</td>\n",
       "      <td>3.555438</td>\n",
       "      <td>-1.997517</td>\n",
       "      <td>-0.867173</td>\n",
       "      <td>-3.192286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000860</td>\n",
       "      <td>-13.205043</td>\n",
       "      <td>35.412796</td>\n",
       "      <td>18.626327</td>\n",
       "      <td>-18.780661</td>\n",
       "      <td>-3.658211</td>\n",
       "      <td>-18.184392</td>\n",
       "      <td>-9.531211</td>\n",
       "      <td>-6.630401</td>\n",
       "      <td>0.281756</td>\n",
       "      <td>...</td>\n",
       "      <td>1.350454</td>\n",
       "      <td>2.436782</td>\n",
       "      <td>-2.068340</td>\n",
       "      <td>-2.313506</td>\n",
       "      <td>1.658322</td>\n",
       "      <td>0.602375</td>\n",
       "      <td>1.434755</td>\n",
       "      <td>0.335589</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>-0.558737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000439</td>\n",
       "      <td>105.578540</td>\n",
       "      <td>-7.727870</td>\n",
       "      <td>-54.957863</td>\n",
       "      <td>12.811952</td>\n",
       "      <td>-0.432278</td>\n",
       "      <td>10.199582</td>\n",
       "      <td>8.024432</td>\n",
       "      <td>48.359902</td>\n",
       "      <td>-5.190777</td>\n",
       "      <td>...</td>\n",
       "      <td>2.226108</td>\n",
       "      <td>-2.637741</td>\n",
       "      <td>2.006790</td>\n",
       "      <td>1.389950</td>\n",
       "      <td>1.592470</td>\n",
       "      <td>0.389373</td>\n",
       "      <td>1.252179</td>\n",
       "      <td>0.232699</td>\n",
       "      <td>-0.899853</td>\n",
       "      <td>5.219488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000318</td>\n",
       "      <td>-7.327347</td>\n",
       "      <td>53.451898</td>\n",
       "      <td>-7.430361</td>\n",
       "      <td>19.708346</td>\n",
       "      <td>-17.924429</td>\n",
       "      <td>-16.075850</td>\n",
       "      <td>-29.364873</td>\n",
       "      <td>-9.784038</td>\n",
       "      <td>-11.851439</td>\n",
       "      <td>...</td>\n",
       "      <td>1.409892</td>\n",
       "      <td>-0.233542</td>\n",
       "      <td>-0.559557</td>\n",
       "      <td>-1.014885</td>\n",
       "      <td>-2.071434</td>\n",
       "      <td>-2.666334</td>\n",
       "      <td>1.868028</td>\n",
       "      <td>-4.059991</td>\n",
       "      <td>3.258332</td>\n",
       "      <td>-0.916755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-001142</td>\n",
       "      <td>-68.076659</td>\n",
       "      <td>-48.781471</td>\n",
       "      <td>-41.877034</td>\n",
       "      <td>-14.293056</td>\n",
       "      <td>-13.285048</td>\n",
       "      <td>10.213185</td>\n",
       "      <td>13.815636</td>\n",
       "      <td>-1.810762</td>\n",
       "      <td>-3.815925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.473048</td>\n",
       "      <td>2.011378</td>\n",
       "      <td>-1.611221</td>\n",
       "      <td>1.318724</td>\n",
       "      <td>-1.446495</td>\n",
       "      <td>-0.874178</td>\n",
       "      <td>0.247021</td>\n",
       "      <td>3.245773</td>\n",
       "      <td>2.598609</td>\n",
       "      <td>2.512914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>ACH-001843</td>\n",
       "      <td>-17.993345</td>\n",
       "      <td>-23.106219</td>\n",
       "      <td>-11.477149</td>\n",
       "      <td>12.734862</td>\n",
       "      <td>10.910127</td>\n",
       "      <td>-2.627428</td>\n",
       "      <td>7.090688</td>\n",
       "      <td>10.285014</td>\n",
       "      <td>7.435539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.943412</td>\n",
       "      <td>6.859956</td>\n",
       "      <td>2.480149</td>\n",
       "      <td>-0.452424</td>\n",
       "      <td>-0.503193</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>-0.062963</td>\n",
       "      <td>-0.691090</td>\n",
       "      <td>0.613382</td>\n",
       "      <td>-4.103107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>ACH-002074</td>\n",
       "      <td>13.293219</td>\n",
       "      <td>-34.315645</td>\n",
       "      <td>124.754849</td>\n",
       "      <td>-4.390610</td>\n",
       "      <td>-27.125356</td>\n",
       "      <td>37.669803</td>\n",
       "      <td>-2.080660</td>\n",
       "      <td>-38.162244</td>\n",
       "      <td>9.140773</td>\n",
       "      <td>...</td>\n",
       "      <td>4.669366</td>\n",
       "      <td>-0.280697</td>\n",
       "      <td>0.362372</td>\n",
       "      <td>-5.373513</td>\n",
       "      <td>-1.182544</td>\n",
       "      <td>-1.003638</td>\n",
       "      <td>1.032190</td>\n",
       "      <td>2.484447</td>\n",
       "      <td>0.706047</td>\n",
       "      <td>-2.601931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>ACH-001164</td>\n",
       "      <td>7.325350</td>\n",
       "      <td>-23.149983</td>\n",
       "      <td>-20.506041</td>\n",
       "      <td>41.769200</td>\n",
       "      <td>-14.242126</td>\n",
       "      <td>21.603492</td>\n",
       "      <td>10.547421</td>\n",
       "      <td>29.343744</td>\n",
       "      <td>2.192337</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.151335</td>\n",
       "      <td>0.336835</td>\n",
       "      <td>1.155761</td>\n",
       "      <td>-0.142555</td>\n",
       "      <td>-6.100099</td>\n",
       "      <td>-1.961802</td>\n",
       "      <td>1.080138</td>\n",
       "      <td>2.045843</td>\n",
       "      <td>-2.425254</td>\n",
       "      <td>-1.723153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>ACH-003180</td>\n",
       "      <td>-53.328758</td>\n",
       "      <td>-50.682140</td>\n",
       "      <td>-29.751308</td>\n",
       "      <td>-13.790538</td>\n",
       "      <td>-17.731040</td>\n",
       "      <td>16.326983</td>\n",
       "      <td>16.623389</td>\n",
       "      <td>-8.590972</td>\n",
       "      <td>-25.676557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792584</td>\n",
       "      <td>1.018562</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>1.362704</td>\n",
       "      <td>2.801868</td>\n",
       "      <td>-1.326434</td>\n",
       "      <td>5.700682</td>\n",
       "      <td>3.146462</td>\n",
       "      <td>-2.676564</td>\n",
       "      <td>-0.628609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>ACH-001979</td>\n",
       "      <td>-16.170992</td>\n",
       "      <td>-29.717532</td>\n",
       "      <td>-23.538599</td>\n",
       "      <td>28.671663</td>\n",
       "      <td>69.967316</td>\n",
       "      <td>30.151250</td>\n",
       "      <td>-13.004348</td>\n",
       "      <td>-10.472141</td>\n",
       "      <td>-12.716238</td>\n",
       "      <td>...</td>\n",
       "      <td>1.147428</td>\n",
       "      <td>-1.338710</td>\n",
       "      <td>-2.190099</td>\n",
       "      <td>5.366385</td>\n",
       "      <td>-0.516462</td>\n",
       "      <td>-1.281901</td>\n",
       "      <td>2.414288</td>\n",
       "      <td>1.410524</td>\n",
       "      <td>-2.320335</td>\n",
       "      <td>-1.177937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1673 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CellLineID         1_0        1_1         1_2        1_3        1_4  \\\n",
       "0     ACH-000873   -8.385960  30.391703   -0.819295  44.671643 -26.321860   \n",
       "1     ACH-000860  -13.205043  35.412796   18.626327 -18.780661  -3.658211   \n",
       "2     ACH-000439  105.578540  -7.727870  -54.957863  12.811952  -0.432278   \n",
       "3     ACH-000318   -7.327347  53.451898   -7.430361  19.708346 -17.924429   \n",
       "4     ACH-001142  -68.076659 -48.781471  -41.877034 -14.293056 -13.285048   \n",
       "...          ...         ...        ...         ...        ...        ...   \n",
       "1668  ACH-001843  -17.993345 -23.106219  -11.477149  12.734862  10.910127   \n",
       "1669  ACH-002074   13.293219 -34.315645  124.754849  -4.390610 -27.125356   \n",
       "1670  ACH-001164    7.325350 -23.149983  -20.506041  41.769200 -14.242126   \n",
       "1671  ACH-003180  -53.328758 -50.682140  -29.751308 -13.790538 -17.731040   \n",
       "1672  ACH-001979  -16.170992 -29.717532  -23.538599  28.671663  69.967316   \n",
       "\n",
       "            1_5        1_6        1_7        1_8  ...     1_490     1_491  \\\n",
       "0      5.701811 -31.807342   9.832625   0.288482  ... -2.321504 -5.421651   \n",
       "1    -18.184392  -9.531211  -6.630401   0.281756  ...  1.350454  2.436782   \n",
       "2     10.199582   8.024432  48.359902  -5.190777  ...  2.226108 -2.637741   \n",
       "3    -16.075850 -29.364873  -9.784038 -11.851439  ...  1.409892 -0.233542   \n",
       "4     10.213185  13.815636  -1.810762  -3.815925  ... -0.473048  2.011378   \n",
       "...         ...        ...        ...        ...  ...       ...       ...   \n",
       "1668  -2.627428   7.090688  10.285014   7.435539  ... -0.943412  6.859956   \n",
       "1669  37.669803  -2.080660 -38.162244   9.140773  ...  4.669366 -0.280697   \n",
       "1670  21.603492  10.547421  29.343744   2.192337  ... -1.151335  0.336835   \n",
       "1671  16.326983  16.623389  -8.590972 -25.676557  ...  0.792584  1.018562   \n",
       "1672  30.151250 -13.004348 -10.472141 -12.716238  ...  1.147428 -1.338710   \n",
       "\n",
       "         1_492     1_493     1_494     1_495     1_496     1_497     1_498  \\\n",
       "0    -1.193897  1.788031  1.495077  1.610082  3.555438 -1.997517 -0.867173   \n",
       "1    -2.068340 -2.313506  1.658322  0.602375  1.434755  0.335589  0.082353   \n",
       "2     2.006790  1.389950  1.592470  0.389373  1.252179  0.232699 -0.899853   \n",
       "3    -0.559557 -1.014885 -2.071434 -2.666334  1.868028 -4.059991  3.258332   \n",
       "4    -1.611221  1.318724 -1.446495 -0.874178  0.247021  3.245773  2.598609   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1668  2.480149 -0.452424 -0.503193 -0.004739 -0.062963 -0.691090  0.613382   \n",
       "1669  0.362372 -5.373513 -1.182544 -1.003638  1.032190  2.484447  0.706047   \n",
       "1670  1.155761 -0.142555 -6.100099 -1.961802  1.080138  2.045843 -2.425254   \n",
       "1671  0.184851  1.362704  2.801868 -1.326434  5.700682  3.146462 -2.676564   \n",
       "1672 -2.190099  5.366385 -0.516462 -1.281901  2.414288  1.410524 -2.320335   \n",
       "\n",
       "         1_499  \n",
       "0    -3.192286  \n",
       "1    -0.558737  \n",
       "2     5.219488  \n",
       "3    -0.916755  \n",
       "4     2.512914  \n",
       "...        ...  \n",
       "1668 -4.103107  \n",
       "1669 -2.601931  \n",
       "1670 -1.723153  \n",
       "1671 -0.628609  \n",
       "1672 -1.177937  \n",
       "\n",
       "[1673 rows x 501 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply scaling method which were used to train individual models\n",
    "\n",
    "# expression: PCA\n",
    "expression_cnv = batch_corrected_expression.iloc[:, 1:]\n",
    "pca_expression = PCA(n_components=500)\n",
    "expression_pca = pca_expression.fit_transform(expression_cnv)\n",
    "expression_pca_df = pd.DataFrame(expression_pca)\n",
    "expression_pca_df.insert(0, \"CellLineID\", batch_corrected_expression[\"CellLineID\"].values)\n",
    "expression_pca_df.columns = ['CellLineID'] + [f\"1_{col}\" for col in expression_pca_df.columns[1:]]\n",
    "expression_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellLineID</th>\n",
       "      <th>2_A2ML1</th>\n",
       "      <th>2_ABCA10</th>\n",
       "      <th>2_ABCA12</th>\n",
       "      <th>2_ABCA13</th>\n",
       "      <th>2_ABCA2</th>\n",
       "      <th>2_ABCA4</th>\n",
       "      <th>2_ABCA5</th>\n",
       "      <th>2_ABCA6</th>\n",
       "      <th>2_ABCA8</th>\n",
       "      <th>...</th>\n",
       "      <th>2_ZNF711</th>\n",
       "      <th>2_ZNF729</th>\n",
       "      <th>2_ZNF750</th>\n",
       "      <th>2_ZNF804B</th>\n",
       "      <th>2_ZNF831</th>\n",
       "      <th>2_ZNF90</th>\n",
       "      <th>2_ZNF99</th>\n",
       "      <th>2_ZRANB3</th>\n",
       "      <th>2_ZSWIM6</th>\n",
       "      <th>2_ZZEF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>ACH-003473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>ACH-003474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>ACH-003475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>ACH-003476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>ACH-003480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1929 rows × 1255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CellLineID  2_A2ML1  2_ABCA10  2_ABCA12  2_ABCA13  2_ABCA2  2_ABCA4  \\\n",
       "0     ACH-000001      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "1     ACH-000002      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "2     ACH-000004      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "3     ACH-000005      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "4     ACH-000006      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "...          ...      ...       ...       ...       ...      ...      ...   \n",
       "1924  ACH-003473      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "1925  ACH-003474      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "1926  ACH-003475      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "1927  ACH-003476      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "1928  ACH-003480      0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "\n",
       "      2_ABCA5  2_ABCA6  2_ABCA8  ...  2_ZNF711  2_ZNF729  2_ZNF750  2_ZNF804B  \\\n",
       "0         0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "1         0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "2         0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "3         0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "4         0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "...       ...      ...      ...  ...       ...       ...       ...        ...   \n",
       "1924      0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "1925      0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "1926      0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "1927      0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "1928      0.0      0.0      0.0  ...       0.0       0.0       0.0        0.0   \n",
       "\n",
       "      2_ZNF831  2_ZNF90  2_ZNF99  2_ZRANB3  2_ZSWIM6  2_ZZEF1  \n",
       "0          0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "1          0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "2          0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "3          0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "4          0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "...        ...      ...      ...       ...       ...      ...  \n",
       "1924       0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "1925       0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "1926       0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "1927       0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "1928       0.0      0.0      0.0       0.0       0.0      0.0  \n",
       "\n",
       "[1929 rows x 1255 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# damaging mutation: Variance threshold + rubust scaling\n",
    "dmg_mut = damaging_mutations.drop(columns=\"CellLineID\")\n",
    "selector_mut = VarianceThreshold(threshold=0.01)\n",
    "dmg_mut_reduced = selector_mut.fit_transform(dmg_mut)\n",
    "selected_columns_mut = dmg_mut.columns[selector_mut.get_support()]\n",
    "scaler_mut = RobustScaler()\n",
    "dmg_mut_reduced = scaler_mut.fit_transform(dmg_mut_reduced) \n",
    "dmg_mut_reduced_df = pd.DataFrame(dmg_mut_reduced, columns=selected_columns_mut)\n",
    "dmg_mut_reduced_df = pd.concat([damaging_mutations[\"CellLineID\"], dmg_mut_reduced_df], axis=1)\n",
    "dmg_mut_reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellLineID</th>\n",
       "      <th>3_0</th>\n",
       "      <th>3_1</th>\n",
       "      <th>3_2</th>\n",
       "      <th>3_3</th>\n",
       "      <th>3_4</th>\n",
       "      <th>3_5</th>\n",
       "      <th>3_6</th>\n",
       "      <th>3_7</th>\n",
       "      <th>3_8</th>\n",
       "      <th>...</th>\n",
       "      <th>3_134</th>\n",
       "      <th>3_135</th>\n",
       "      <th>3_136</th>\n",
       "      <th>3_137</th>\n",
       "      <th>3_138</th>\n",
       "      <th>3_139</th>\n",
       "      <th>3_140</th>\n",
       "      <th>3_141</th>\n",
       "      <th>3_142</th>\n",
       "      <th>3_143</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000698</td>\n",
       "      <td>-0.612917</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>0.606426</td>\n",
       "      <td>0.721333</td>\n",
       "      <td>0.110235</td>\n",
       "      <td>0.179933</td>\n",
       "      <td>-0.114938</td>\n",
       "      <td>-0.940047</td>\n",
       "      <td>-0.957034</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.062067</td>\n",
       "      <td>2.484835</td>\n",
       "      <td>-0.517883</td>\n",
       "      <td>-1.016179</td>\n",
       "      <td>1.475021</td>\n",
       "      <td>-0.654903</td>\n",
       "      <td>-0.819080</td>\n",
       "      <td>-0.021027</td>\n",
       "      <td>-0.314445</td>\n",
       "      <td>-0.504282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000489</td>\n",
       "      <td>1.649916</td>\n",
       "      <td>-1.009740</td>\n",
       "      <td>-0.200529</td>\n",
       "      <td>0.038992</td>\n",
       "      <td>1.579026</td>\n",
       "      <td>-0.893064</td>\n",
       "      <td>-0.443334</td>\n",
       "      <td>-0.060601</td>\n",
       "      <td>0.154512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.980290</td>\n",
       "      <td>6.054042</td>\n",
       "      <td>0.067953</td>\n",
       "      <td>0.662172</td>\n",
       "      <td>1.235912</td>\n",
       "      <td>-0.275541</td>\n",
       "      <td>0.767357</td>\n",
       "      <td>0.444319</td>\n",
       "      <td>-0.646511</td>\n",
       "      <td>-0.023882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000431</td>\n",
       "      <td>0.039605</td>\n",
       "      <td>0.282172</td>\n",
       "      <td>-0.324024</td>\n",
       "      <td>0.340225</td>\n",
       "      <td>-0.044571</td>\n",
       "      <td>0.972972</td>\n",
       "      <td>-0.527327</td>\n",
       "      <td>-0.154960</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.185110</td>\n",
       "      <td>-0.428942</td>\n",
       "      <td>-0.700518</td>\n",
       "      <td>2.254630</td>\n",
       "      <td>-0.697849</td>\n",
       "      <td>-0.651034</td>\n",
       "      <td>-0.850240</td>\n",
       "      <td>0.602303</td>\n",
       "      <td>-0.906461</td>\n",
       "      <td>1.634607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000707</td>\n",
       "      <td>0.485446</td>\n",
       "      <td>-0.428368</td>\n",
       "      <td>-0.400411</td>\n",
       "      <td>-0.041245</td>\n",
       "      <td>-1.136608</td>\n",
       "      <td>0.183832</td>\n",
       "      <td>-1.495605</td>\n",
       "      <td>0.244413</td>\n",
       "      <td>-0.756761</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331765</td>\n",
       "      <td>-0.183950</td>\n",
       "      <td>-0.809336</td>\n",
       "      <td>-0.026228</td>\n",
       "      <td>0.948358</td>\n",
       "      <td>2.253929</td>\n",
       "      <td>-3.090354</td>\n",
       "      <td>-1.461826</td>\n",
       "      <td>2.234051</td>\n",
       "      <td>0.081316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000509</td>\n",
       "      <td>-1.414293</td>\n",
       "      <td>-0.394963</td>\n",
       "      <td>-0.423156</td>\n",
       "      <td>-0.781748</td>\n",
       "      <td>-0.612832</td>\n",
       "      <td>-0.349126</td>\n",
       "      <td>0.679537</td>\n",
       "      <td>-1.288470</td>\n",
       "      <td>0.694292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936852</td>\n",
       "      <td>-0.168559</td>\n",
       "      <td>-0.738633</td>\n",
       "      <td>-0.710741</td>\n",
       "      <td>-0.760559</td>\n",
       "      <td>2.050669</td>\n",
       "      <td>-0.334478</td>\n",
       "      <td>-0.368402</td>\n",
       "      <td>-0.982283</td>\n",
       "      <td>1.228356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>ACH-000428</td>\n",
       "      <td>0.110377</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.137401</td>\n",
       "      <td>-0.395569</td>\n",
       "      <td>-0.221911</td>\n",
       "      <td>1.067014</td>\n",
       "      <td>0.336480</td>\n",
       "      <td>-0.960471</td>\n",
       "      <td>0.388553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300115</td>\n",
       "      <td>0.262923</td>\n",
       "      <td>0.710310</td>\n",
       "      <td>0.230650</td>\n",
       "      <td>-0.365990</td>\n",
       "      <td>-0.371611</td>\n",
       "      <td>0.641735</td>\n",
       "      <td>-0.390669</td>\n",
       "      <td>0.906651</td>\n",
       "      <td>-0.327067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>ACH-000655</td>\n",
       "      <td>-0.269672</td>\n",
       "      <td>0.251754</td>\n",
       "      <td>-0.863469</td>\n",
       "      <td>-0.349136</td>\n",
       "      <td>-1.260717</td>\n",
       "      <td>-0.185840</td>\n",
       "      <td>-0.195436</td>\n",
       "      <td>-0.649806</td>\n",
       "      <td>-0.837895</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.029560</td>\n",
       "      <td>-0.317276</td>\n",
       "      <td>-0.255798</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>-0.209949</td>\n",
       "      <td>-0.458913</td>\n",
       "      <td>-0.094344</td>\n",
       "      <td>-1.043973</td>\n",
       "      <td>-1.472114</td>\n",
       "      <td>-0.579963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>ACH-000273</td>\n",
       "      <td>-1.326400</td>\n",
       "      <td>2.067889</td>\n",
       "      <td>-0.875423</td>\n",
       "      <td>0.569805</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>-0.113267</td>\n",
       "      <td>0.732226</td>\n",
       "      <td>-0.177328</td>\n",
       "      <td>1.495660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.670747</td>\n",
       "      <td>-1.012161</td>\n",
       "      <td>-0.585764</td>\n",
       "      <td>-0.377737</td>\n",
       "      <td>-0.285001</td>\n",
       "      <td>-0.276757</td>\n",
       "      <td>-0.173452</td>\n",
       "      <td>-1.107292</td>\n",
       "      <td>0.207267</td>\n",
       "      <td>0.561858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>ACH-000504</td>\n",
       "      <td>-0.783560</td>\n",
       "      <td>0.911902</td>\n",
       "      <td>-0.418151</td>\n",
       "      <td>-0.612986</td>\n",
       "      <td>-0.056590</td>\n",
       "      <td>-0.310806</td>\n",
       "      <td>0.402894</td>\n",
       "      <td>-0.442600</td>\n",
       "      <td>0.504737</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.541053</td>\n",
       "      <td>-0.800185</td>\n",
       "      <td>-0.505402</td>\n",
       "      <td>0.393043</td>\n",
       "      <td>-0.357944</td>\n",
       "      <td>-0.497675</td>\n",
       "      <td>0.491758</td>\n",
       "      <td>-0.902171</td>\n",
       "      <td>-1.446228</td>\n",
       "      <td>-0.568729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>ACH-000825</td>\n",
       "      <td>0.179631</td>\n",
       "      <td>-0.442430</td>\n",
       "      <td>0.508123</td>\n",
       "      <td>-0.548139</td>\n",
       "      <td>-0.589678</td>\n",
       "      <td>-0.443838</td>\n",
       "      <td>-1.691261</td>\n",
       "      <td>-1.011119</td>\n",
       "      <td>-1.059837</td>\n",
       "      <td>...</td>\n",
       "      <td>1.315408</td>\n",
       "      <td>-0.691232</td>\n",
       "      <td>1.975236</td>\n",
       "      <td>-0.156967</td>\n",
       "      <td>1.145041</td>\n",
       "      <td>-0.469878</td>\n",
       "      <td>0.824593</td>\n",
       "      <td>-1.216955</td>\n",
       "      <td>0.994209</td>\n",
       "      <td>-0.373266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CellLineID       3_0       3_1       3_2       3_3       3_4       3_5  \\\n",
       "0    ACH-000698 -0.612917  0.223323  0.606426  0.721333  0.110235  0.179933   \n",
       "1    ACH-000489  1.649916 -1.009740 -0.200529  0.038992  1.579026 -0.893064   \n",
       "2    ACH-000431  0.039605  0.282172 -0.324024  0.340225 -0.044571  0.972972   \n",
       "3    ACH-000707  0.485446 -0.428368 -0.400411 -0.041245 -1.136608  0.183832   \n",
       "4    ACH-000509 -1.414293 -0.394963 -0.423156 -0.781748 -0.612832 -0.349126   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "894  ACH-000428  0.110377  0.391061  0.137401 -0.395569 -0.221911  1.067014   \n",
       "895  ACH-000655 -0.269672  0.251754 -0.863469 -0.349136 -1.260717 -0.185840   \n",
       "896  ACH-000273 -1.326400  2.067889 -0.875423  0.569805  0.003275 -0.113267   \n",
       "897  ACH-000504 -0.783560  0.911902 -0.418151 -0.612986 -0.056590 -0.310806   \n",
       "898  ACH-000825  0.179631 -0.442430  0.508123 -0.548139 -0.589678 -0.443838   \n",
       "\n",
       "          3_6       3_7       3_8  ...     3_134     3_135     3_136  \\\n",
       "0   -0.114938 -0.940047 -0.957034  ... -1.062067  2.484835 -0.517883   \n",
       "1   -0.443334 -0.060601  0.154512  ...  1.980290  6.054042  0.067953   \n",
       "2   -0.527327 -0.154960  0.964029  ... -1.185110 -0.428942 -0.700518   \n",
       "3   -1.495605  0.244413 -0.756761  ... -1.331765 -0.183950 -0.809336   \n",
       "4    0.679537 -1.288470  0.694292  ...  0.936852 -0.168559 -0.738633   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "894  0.336480 -0.960471  0.388553  ... -0.300115  0.262923  0.710310   \n",
       "895 -0.195436 -0.649806 -0.837895  ... -1.029560 -0.317276 -0.255798   \n",
       "896  0.732226 -0.177328  1.495660  ... -0.670747 -1.012161 -0.585764   \n",
       "897  0.402894 -0.442600  0.504737  ... -1.541053 -0.800185 -0.505402   \n",
       "898 -1.691261 -1.011119 -1.059837  ...  1.315408 -0.691232  1.975236   \n",
       "\n",
       "        3_137     3_138     3_139     3_140     3_141     3_142     3_143  \n",
       "0   -1.016179  1.475021 -0.654903 -0.819080 -0.021027 -0.314445 -0.504282  \n",
       "1    0.662172  1.235912 -0.275541  0.767357  0.444319 -0.646511 -0.023882  \n",
       "2    2.254630 -0.697849 -0.651034 -0.850240  0.602303 -0.906461  1.634607  \n",
       "3   -0.026228  0.948358  2.253929 -3.090354 -1.461826  2.234051  0.081316  \n",
       "4   -0.710741 -0.760559  2.050669 -0.334478 -0.368402 -0.982283  1.228356  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "894  0.230650 -0.365990 -0.371611  0.641735 -0.390669  0.906651 -0.327067  \n",
       "895 -0.686808 -0.209949 -0.458913 -0.094344 -1.043973 -1.472114 -0.579963  \n",
       "896 -0.377737 -0.285001 -0.276757 -0.173452 -1.107292  0.207267  0.561858  \n",
       "897  0.393043 -0.357944 -0.497675  0.491758 -0.902171 -1.446228 -0.568729  \n",
       "898 -0.156967  1.145041 -0.469878  0.824593 -1.216955  0.994209 -0.373266  \n",
       "\n",
       "[899 rows x 145 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# protein: standard scaler\n",
    "prot = harmonized_RPPA.drop(columns=\"CellLineID\")\n",
    "scaler_protein = StandardScaler()\n",
    "protein_scaled = scaler_protein.fit_transform(prot)\n",
    "protein_scaled_df = pd.DataFrame(protein_scaled)\n",
    "protein_scaled_df.insert(0, \"CellLineID\", harmonized_RPPA[\"CellLineID\"].values)\n",
    "protein_scaled_df.columns = ['CellLineID'] + [f\"3_{col}\" for col in protein_scaled_df.columns[1:]]\n",
    "protein_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellLineID</th>\n",
       "      <th>4_0</th>\n",
       "      <th>4_1</th>\n",
       "      <th>4_2</th>\n",
       "      <th>4_3</th>\n",
       "      <th>4_4</th>\n",
       "      <th>4_5</th>\n",
       "      <th>4_6</th>\n",
       "      <th>4_7</th>\n",
       "      <th>4_8</th>\n",
       "      <th>...</th>\n",
       "      <th>4_529</th>\n",
       "      <th>4_530</th>\n",
       "      <th>4_531</th>\n",
       "      <th>4_532</th>\n",
       "      <th>4_533</th>\n",
       "      <th>4_534</th>\n",
       "      <th>4_535</th>\n",
       "      <th>4_536</th>\n",
       "      <th>4_537</th>\n",
       "      <th>4_538</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000001</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000002</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000004</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000005</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000006</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>ACH-003473</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>ACH-003474</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>ACH-003475</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>ACH-003476</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>ACH-003480</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.030561</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.050978</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.032216</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.022774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1929 rows × 540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CellLineID       4_0       4_1       4_2       4_3       4_4       4_5  \\\n",
       "0     ACH-000001 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "1     ACH-000002 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "2     ACH-000004 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "3     ACH-000005 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "4     ACH-000006 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1924  ACH-003473 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "1925  ACH-003474 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "1926  ACH-003475 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "1927  ACH-003476 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "1928  ACH-003480 -0.032216 -0.022774 -0.022774 -0.022774 -0.022774 -0.030561   \n",
       "\n",
       "           4_6       4_7       4_8  ...     4_529     4_530     4_531  \\\n",
       "0    -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "1    -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "2    -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "3    -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "4    -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1924 -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "1925 -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "1926 -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "1927 -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "1928 -0.032216 -0.022774 -0.032216  ... -0.022774 -0.050978 -0.032216   \n",
       "\n",
       "         4_532     4_533     4_534     4_535     4_536     4_537     4_538  \n",
       "0    -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "1    -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "2    -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "3    -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "4    -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1924 -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "1925 -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "1926 -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "1927 -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "1928 -0.022774 -0.032216 -0.039467 -0.022774 -0.032216 -0.022774 -0.022774  \n",
       "\n",
       "[1929 rows x 540 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hotspot mutation: standard scaler\n",
    "hot_mut = hotspot_mutations.drop(columns=\"CellLineID\")\n",
    "scaler_hotspot = StandardScaler()\n",
    "hotspot_scaled = scaler_hotspot.fit_transform(hot_mut)\n",
    "hotspot_scaled_df = pd.DataFrame(hotspot_scaled)\n",
    "hotspot_scaled_df.insert(0, \"CellLineID\", hotspot_mutations[\"CellLineID\"].values)\n",
    "hotspot_scaled_df.columns = ['CellLineID'] + [f\"4_{col}\" for col in hotspot_scaled_df.columns[1:]]\n",
    "hotspot_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellLineID</th>\n",
       "      <th>5_0</th>\n",
       "      <th>5_1</th>\n",
       "      <th>5_2</th>\n",
       "      <th>5_3</th>\n",
       "      <th>5_4</th>\n",
       "      <th>5_5</th>\n",
       "      <th>5_6</th>\n",
       "      <th>5_7</th>\n",
       "      <th>5_8</th>\n",
       "      <th>...</th>\n",
       "      <th>5_215</th>\n",
       "      <th>5_216</th>\n",
       "      <th>5_217</th>\n",
       "      <th>5_218</th>\n",
       "      <th>5_219</th>\n",
       "      <th>5_220</th>\n",
       "      <th>5_221</th>\n",
       "      <th>5_222</th>\n",
       "      <th>5_223</th>\n",
       "      <th>5_224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH-000698</td>\n",
       "      <td>0.557284</td>\n",
       "      <td>0.515189</td>\n",
       "      <td>-0.054878</td>\n",
       "      <td>0.135187</td>\n",
       "      <td>-1.043681</td>\n",
       "      <td>-0.129531</td>\n",
       "      <td>0.414312</td>\n",
       "      <td>-0.638396</td>\n",
       "      <td>-0.129797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513798</td>\n",
       "      <td>0.426691</td>\n",
       "      <td>0.353608</td>\n",
       "      <td>0.708122</td>\n",
       "      <td>1.060755</td>\n",
       "      <td>0.750534</td>\n",
       "      <td>-0.028667</td>\n",
       "      <td>0.681854</td>\n",
       "      <td>0.339773</td>\n",
       "      <td>0.172341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH-000489</td>\n",
       "      <td>-1.153386</td>\n",
       "      <td>-0.455615</td>\n",
       "      <td>-1.561702</td>\n",
       "      <td>0.352185</td>\n",
       "      <td>-0.099291</td>\n",
       "      <td>-0.252544</td>\n",
       "      <td>-0.036573</td>\n",
       "      <td>-0.363507</td>\n",
       "      <td>-0.471001</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023767</td>\n",
       "      <td>1.569556</td>\n",
       "      <td>1.036571</td>\n",
       "      <td>0.879770</td>\n",
       "      <td>1.033590</td>\n",
       "      <td>1.087359</td>\n",
       "      <td>0.433064</td>\n",
       "      <td>2.113894</td>\n",
       "      <td>1.574201</td>\n",
       "      <td>0.873145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH-000431</td>\n",
       "      <td>-0.165981</td>\n",
       "      <td>-0.936554</td>\n",
       "      <td>-0.737158</td>\n",
       "      <td>-0.318869</td>\n",
       "      <td>-0.548701</td>\n",
       "      <td>-0.109933</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.103380</td>\n",
       "      <td>-0.509048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149783</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>-0.248786</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>0.518728</td>\n",
       "      <td>-0.264772</td>\n",
       "      <td>-0.578523</td>\n",
       "      <td>-0.130029</td>\n",
       "      <td>-0.230330</td>\n",
       "      <td>-0.782058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH-000707</td>\n",
       "      <td>-0.537852</td>\n",
       "      <td>0.720730</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>-1.228664</td>\n",
       "      <td>-0.212848</td>\n",
       "      <td>0.672876</td>\n",
       "      <td>1.097971</td>\n",
       "      <td>0.297578</td>\n",
       "      <td>0.747467</td>\n",
       "      <td>...</td>\n",
       "      <td>1.790577</td>\n",
       "      <td>0.381808</td>\n",
       "      <td>0.808239</td>\n",
       "      <td>0.689492</td>\n",
       "      <td>0.454086</td>\n",
       "      <td>0.341955</td>\n",
       "      <td>-0.245347</td>\n",
       "      <td>0.908357</td>\n",
       "      <td>-0.239624</td>\n",
       "      <td>0.638919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH-000509</td>\n",
       "      <td>-1.462500</td>\n",
       "      <td>-1.268864</td>\n",
       "      <td>1.120189</td>\n",
       "      <td>0.882626</td>\n",
       "      <td>-2.099762</td>\n",
       "      <td>-0.049797</td>\n",
       "      <td>1.287728</td>\n",
       "      <td>-0.950836</td>\n",
       "      <td>-0.238966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776029</td>\n",
       "      <td>1.899423</td>\n",
       "      <td>1.746608</td>\n",
       "      <td>1.610213</td>\n",
       "      <td>1.932546</td>\n",
       "      <td>1.219787</td>\n",
       "      <td>1.706747</td>\n",
       "      <td>1.530576</td>\n",
       "      <td>1.395632</td>\n",
       "      <td>1.867989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>ACH-000655</td>\n",
       "      <td>0.125581</td>\n",
       "      <td>0.490805</td>\n",
       "      <td>1.064821</td>\n",
       "      <td>0.467987</td>\n",
       "      <td>0.148612</td>\n",
       "      <td>-0.509327</td>\n",
       "      <td>0.434753</td>\n",
       "      <td>2.158001</td>\n",
       "      <td>-0.717929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979465</td>\n",
       "      <td>-0.554915</td>\n",
       "      <td>-0.858667</td>\n",
       "      <td>-0.838440</td>\n",
       "      <td>-1.267921</td>\n",
       "      <td>-1.512691</td>\n",
       "      <td>-0.924243</td>\n",
       "      <td>-0.767200</td>\n",
       "      <td>-1.760266</td>\n",
       "      <td>-0.776712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>ACH-000273</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.694197</td>\n",
       "      <td>-1.154972</td>\n",
       "      <td>0.568667</td>\n",
       "      <td>-0.299668</td>\n",
       "      <td>-0.864138</td>\n",
       "      <td>1.470717</td>\n",
       "      <td>0.497303</td>\n",
       "      <td>-0.673935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.506716</td>\n",
       "      <td>-0.674703</td>\n",
       "      <td>-0.527957</td>\n",
       "      <td>-1.083407</td>\n",
       "      <td>-1.467146</td>\n",
       "      <td>-1.595997</td>\n",
       "      <td>-1.068780</td>\n",
       "      <td>-0.788050</td>\n",
       "      <td>-1.343282</td>\n",
       "      <td>-0.881662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>ACH-000504</td>\n",
       "      <td>0.093852</td>\n",
       "      <td>0.190556</td>\n",
       "      <td>-0.585055</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.334694</td>\n",
       "      <td>-1.480546</td>\n",
       "      <td>0.305665</td>\n",
       "      <td>1.356817</td>\n",
       "      <td>-0.959219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.814866</td>\n",
       "      <td>-1.437779</td>\n",
       "      <td>-0.743024</td>\n",
       "      <td>-0.989967</td>\n",
       "      <td>-1.340031</td>\n",
       "      <td>-1.103159</td>\n",
       "      <td>-0.890545</td>\n",
       "      <td>-1.521454</td>\n",
       "      <td>-1.565363</td>\n",
       "      <td>-1.533381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>ACH-000825</td>\n",
       "      <td>0.076940</td>\n",
       "      <td>0.383840</td>\n",
       "      <td>0.711219</td>\n",
       "      <td>-0.115915</td>\n",
       "      <td>0.690186</td>\n",
       "      <td>-0.086400</td>\n",
       "      <td>0.299768</td>\n",
       "      <td>1.142896</td>\n",
       "      <td>-0.344986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169536</td>\n",
       "      <td>0.691391</td>\n",
       "      <td>0.728826</td>\n",
       "      <td>0.445061</td>\n",
       "      <td>-0.090201</td>\n",
       "      <td>-0.217227</td>\n",
       "      <td>0.107072</td>\n",
       "      <td>0.873816</td>\n",
       "      <td>0.321537</td>\n",
       "      <td>0.919807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>ACH-000084</td>\n",
       "      <td>1.259098</td>\n",
       "      <td>-0.185423</td>\n",
       "      <td>-0.919277</td>\n",
       "      <td>1.533305</td>\n",
       "      <td>-1.084176</td>\n",
       "      <td>1.549760</td>\n",
       "      <td>1.224877</td>\n",
       "      <td>-1.419783</td>\n",
       "      <td>-0.610399</td>\n",
       "      <td>...</td>\n",
       "      <td>1.995336</td>\n",
       "      <td>1.374493</td>\n",
       "      <td>1.725812</td>\n",
       "      <td>1.966011</td>\n",
       "      <td>1.581082</td>\n",
       "      <td>0.118065</td>\n",
       "      <td>0.164940</td>\n",
       "      <td>1.729493</td>\n",
       "      <td>1.941224</td>\n",
       "      <td>1.794396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>927 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CellLineID       5_0       5_1       5_2       5_3       5_4       5_5  \\\n",
       "0    ACH-000698  0.557284  0.515189 -0.054878  0.135187 -1.043681 -0.129531   \n",
       "1    ACH-000489 -1.153386 -0.455615 -1.561702  0.352185 -0.099291 -0.252544   \n",
       "2    ACH-000431 -0.165981 -0.936554 -0.737158 -0.318869 -0.548701 -0.109933   \n",
       "3    ACH-000707 -0.537852  0.720730  0.590426 -1.228664 -0.212848  0.672876   \n",
       "4    ACH-000509 -1.462500 -1.268864  1.120189  0.882626 -2.099762 -0.049797   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "922  ACH-000655  0.125581  0.490805  1.064821  0.467987  0.148612 -0.509327   \n",
       "923  ACH-000273  0.060382  0.694197 -1.154972  0.568667 -0.299668 -0.864138   \n",
       "924  ACH-000504  0.093852  0.190556 -0.585055  0.000092  0.334694 -1.480546   \n",
       "925  ACH-000825  0.076940  0.383840  0.711219 -0.115915  0.690186 -0.086400   \n",
       "926  ACH-000084  1.259098 -0.185423 -0.919277  1.533305 -1.084176  1.549760   \n",
       "\n",
       "          5_6       5_7       5_8  ...     5_215     5_216     5_217  \\\n",
       "0    0.414312 -0.638396 -0.129797  ...  0.513798  0.426691  0.353608   \n",
       "1   -0.036573 -0.363507 -0.471001  ...  1.023767  1.569556  1.036571   \n",
       "2   -0.005529 -0.103380 -0.509048  ...  0.149783  0.000650 -0.248786   \n",
       "3    1.097971  0.297578  0.747467  ...  1.790577  0.381808  0.808239   \n",
       "4    1.287728 -0.950836 -0.238966  ...  0.776029  1.899423  1.746608   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "922  0.434753  2.158001 -0.717929  ... -0.979465 -0.554915 -0.858667   \n",
       "923  1.470717  0.497303 -0.673935  ... -0.506716 -0.674703 -0.527957   \n",
       "924  0.305665  1.356817 -0.959219  ... -0.814866 -1.437779 -0.743024   \n",
       "925  0.299768  1.142896 -0.344986  ...  0.169536  0.691391  0.728826   \n",
       "926  1.224877 -1.419783 -0.610399  ...  1.995336  1.374493  1.725812   \n",
       "\n",
       "        5_218     5_219     5_220     5_221     5_222     5_223     5_224  \n",
       "0    0.708122  1.060755  0.750534 -0.028667  0.681854  0.339773  0.172341  \n",
       "1    0.879770  1.033590  1.087359  0.433064  2.113894  1.574201  0.873145  \n",
       "2   -0.001200  0.518728 -0.264772 -0.578523 -0.130029 -0.230330 -0.782058  \n",
       "3    0.689492  0.454086  0.341955 -0.245347  0.908357 -0.239624  0.638919  \n",
       "4    1.610213  1.932546  1.219787  1.706747  1.530576  1.395632  1.867989  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "922 -0.838440 -1.267921 -1.512691 -0.924243 -0.767200 -1.760266 -0.776712  \n",
       "923 -1.083407 -1.467146 -1.595997 -1.068780 -0.788050 -1.343282 -0.881662  \n",
       "924 -0.989967 -1.340031 -1.103159 -0.890545 -1.521454 -1.565363 -1.533381  \n",
       "925  0.445061 -0.090201 -0.217227  0.107072  0.873816  0.321537  0.919807  \n",
       "926  1.966011  1.581082  0.118065  0.164940  1.729493  1.941224  1.794396  \n",
       "\n",
       "[927 rows x 226 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metabolomics: standard scaler\n",
    "meta = metabolomics.drop(columns=\"CellLineID\")\n",
    "scaler_metabolomics = StandardScaler()\n",
    "metabolomics_scaled = scaler_metabolomics.fit_transform(meta)\n",
    "metabolomics_scaled_df = pd.DataFrame(metabolomics_scaled)\n",
    "metabolomics_scaled_df.insert(0, \"CellLineID\", metabolomics[\"CellLineID\"].values)\n",
    "metabolomics_scaled_df.columns = ['CellLineID'] + [f\"5_{col}\" for col in metabolomics_scaled_df.columns[1:]]\n",
    "metabolomics_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miRNA: standard scaler\n",
    "rna = miRNA_expression.drop(columns=\"CellLineID\")\n",
    "scaler_miRNA = StandardScaler()\n",
    "miRNA_scaled = scaler_miRNA.fit_transform(rna)\n",
    "miRNA_scaled_df = pd.DataFrame(miRNA_scaled)\n",
    "miRNA_scaled_df.insert(0, \"CellLineID\", miRNA_expression[\"CellLineID\"].values)\n",
    "miRNA_scaled_df.columns = ['CellLineID'] + [f\"6_{col}\" for col in miRNA_scaled_df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy number: PCA\n",
    "CN_cnv = absolute_copy_number.iloc[:, 1:]\n",
    "pca_CN = PCA(n_components=500)\n",
    "CN_pca = pca_CN.fit_transform(CN_cnv)\n",
    "CN_pca_df = pd.DataFrame(CN_pca)\n",
    "CN_pca_df.insert(0, \"CellLineID\", absolute_copy_number[\"CellLineID\"].values)\n",
    "CN_pca_df.columns = ['CellLineID'] + [f\"7_{col}\" for col in CN_pca_df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC: log transform\n",
    "epsilon = 1e-10  # prevent zero division\n",
    "y = IC50_AUC_CLS[[\"AUC\", \"IC50\"]]\n",
    "y_array = y.to_numpy(dtype=np.float32)\n",
    "y_array[:, 0] = np.log10(np.where(y_array[:, 0] == 0, epsilon, y_array[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IC50: minmax scaling\n",
    "scaler_IC50 = MinMaxScaler()\n",
    "y_array[:, 1] = scaler_IC50.fit_transform(y_array[:, 1].reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC50_AUC_CLS[\"AUC\"] = y_array[:, 0]\n",
    "IC50_AUC_CLS[\"IC50\"] = y_array[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59303, 3900)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save each data's feature name, and merge everything\n",
    "expression_n = expression_pca_df.columns.tolist()\n",
    "dmg_mut_n = dmg_mut_reduced_df.columns.tolist()\n",
    "protein_n = protein_scaled_df.columns.tolist()\n",
    "hot_mut_n = hotspot_scaled_df.columns.tolist()\n",
    "meta_n = metabolomics_scaled_df.columns.tolist()\n",
    "RNA_n = miRNA_scaled_df.columns.tolist()\n",
    "CN_n = CN_pca_df.columns.tolist()\n",
    "IC50_AUC_CLS_n = IC50_AUC_CLS.columns.tolist()\n",
    "\n",
    "all_data = dmg_mut_reduced_df.merge(expression_pca_df, on='CellLineID', how = 'inner')\n",
    "all_data = all_data.merge(protein_scaled_df, on='CellLineID', how = 'inner')\n",
    "all_data = all_data.merge(hotspot_scaled_df, on='CellLineID', how = 'inner')\n",
    "all_data = all_data.merge(metabolomics_scaled_df, on='CellLineID', how = 'inner')\n",
    "all_data = all_data.merge(miRNA_scaled_df, on='CellLineID', how = 'inner')\n",
    "all_data = all_data.merge(CN_pca_df, on='CellLineID', how = 'inner')\n",
    "all_data = all_data.merge(IC50_AUC_CLS, on='CellLineID', how = 'inner')\n",
    "\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19736\\1659156920.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  cls_tensor = torch.tensor(cls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_smiles shape = torch.Size([48034, 768])\n",
      "val_smiles shape = torch.Size([5338, 768])\n",
      "test_smiles shape = torch.Size([5931, 768])\n",
      "train_expression shape = torch.Size([48034, 500])\n",
      "val_expression shape = torch.Size([5338, 500])\n",
      "test_expression shape = torch.Size([5931, 500])\n",
      "train_damaging_mutation shape = torch.Size([48034, 1254])\n",
      "val_damaging_mutation shape = torch.Size([5338, 1254])\n",
      "test_damaging_mutation shape = torch.Size([5931, 1254])\n",
      "train_protein shape = torch.Size([48034, 144])\n",
      "val_protein shape = torch.Size([5338, 144])\n",
      "test_protein shape = torch.Size([5931, 144])\n",
      "train_hotspot_mutation shape = torch.Size([48034, 539])\n",
      "val_hotspot_mutation shape = torch.Size([5338, 539])\n",
      "test_hotspot_mutation shape = torch.Size([5931, 539])\n",
      "train_metabolomic shape = torch.Size([48034, 225])\n",
      "val_metabolomic shape = torch.Size([5338, 225])\n",
      "test_metabolomic shape = torch.Size([5931, 225])\n",
      "train_miRNA shape = torch.Size([48034, 734])\n",
      "val_miRNA shape = torch.Size([5338, 734])\n",
      "test_miRNA shape = torch.Size([5931, 734])\n",
      "train_copy_number shape = torch.Size([48034, 500])\n",
      "val_copy_number shape = torch.Size([5338, 500])\n",
      "test_copy_number shape = torch.Size([5931, 500])\n",
      "train_y shape = torch.Size([48034, 2])\n",
      "val_y shape = torch.Size([5338, 2])\n",
      "test_y shape = torch.Size([5931, 2])\n"
     ]
    }
   ],
   "source": [
    "# re-separate \n",
    "expression = all_data[expression_n[1:]]\n",
    "damaging_mutation = all_data[dmg_mut_n[1:]]\n",
    "protein = all_data[protein_n[1:]]\n",
    "hotspot_mutation = all_data[hot_mut_n[1:]]\n",
    "metabolomic = all_data[meta_n[1:]]\n",
    "miRNA = all_data[RNA_n[1:]]\n",
    "copy_number = all_data[CN_n[1:]]\n",
    "target = all_data[[\"AUC\", \"IC50\"]]\n",
    "cls = all_data[\"CLS\"]\n",
    "\n",
    "# convert to tensor\n",
    "expression_tensor = torch.tensor(expression.to_numpy(dtype=np.float32))\n",
    "damaging_mutation_tensor = torch.tensor(damaging_mutation.to_numpy(dtype=np.float32))\n",
    "protein_tensor = torch.tensor(protein.to_numpy(dtype=np.float32))\n",
    "hotspot_mutation_tensor = torch.tensor(hotspot_mutation.to_numpy(dtype=np.float32))\n",
    "metabolomic_tensor = torch.tensor(metabolomic.to_numpy(dtype=np.float32))\n",
    "miRNA_tensor = torch.tensor(miRNA.to_numpy(dtype=np.float32))\n",
    "copy_number_tensor = torch.tensor(copy_number.to_numpy(dtype=np.float32))\n",
    "target_tensor = torch.tensor(target.to_numpy(dtype=np.float32))\n",
    "cls_tensor = torch.tensor(cls)\n",
    "\n",
    "# train, validation, test split\n",
    "train_smiles, test_smiles, train_expression, test_expression, train_damaging_mutation, test_damaging_mutation, train_protein, test_protein, train_hotspot_mutation, test_hotspot_mutation, train_metabolomic, test_metabolomic, train_miRNA, test_miRNA, train_copy_number, test_copy_number, train_y, test_y = train_test_split(\n",
    "    cls_tensor, expression_tensor, damaging_mutation_tensor, protein_tensor, hotspot_mutation_tensor, metabolomic_tensor, miRNA_tensor, copy_number_tensor, target_tensor, test_size=0.1, random_state=42)\n",
    "\n",
    "train_smiles, val_smiles, train_expression, val_expression, train_damaging_mutation, val_damaging_mutation, train_protein, val_protein, train_hotspot_mutation, val_hotspot_mutation, train_metabolomic, val_metabolomic, train_miRNA, val_miRNA, train_copy_number, val_copy_number, train_y, val_y = train_test_split(\n",
    "    train_smiles, train_expression, train_damaging_mutation, train_protein, train_hotspot_mutation, train_metabolomic, train_miRNA, train_copy_number, train_y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"train_smiles shape =\", train_smiles.shape)\n",
    "print(\"val_smiles shape =\", val_smiles.shape)\n",
    "print(\"test_smiles shape =\", test_smiles.shape)\n",
    "print(\"train_expression shape =\", train_expression.shape)\n",
    "print(\"val_expression shape =\", val_expression.shape)\n",
    "print(\"test_expression shape =\", test_expression.shape)\n",
    "print(\"train_damaging_mutation shape =\", train_damaging_mutation.shape)\n",
    "print(\"val_damaging_mutation shape =\", val_damaging_mutation.shape)\n",
    "print(\"test_damaging_mutation shape =\", test_damaging_mutation.shape)\n",
    "print(\"train_protein shape =\", train_protein.shape)\n",
    "print(\"val_protein shape =\", val_protein.shape)\n",
    "print(\"test_protein shape =\", test_protein.shape)\n",
    "print(\"train_hotspot_mutation shape =\", train_hotspot_mutation.shape)\n",
    "print(\"val_hotspot_mutation shape =\", val_hotspot_mutation.shape)\n",
    "print(\"test_hotspot_mutation shape =\", test_hotspot_mutation.shape)\n",
    "print(\"train_metabolomic shape =\", train_metabolomic.shape)\n",
    "print(\"val_metabolomic shape =\", val_metabolomic.shape)\n",
    "print(\"test_metabolomic shape =\", test_metabolomic.shape)\n",
    "print(\"train_miRNA shape =\", train_miRNA.shape)\n",
    "print(\"val_miRNA shape =\", val_miRNA.shape)\n",
    "print(\"test_miRNA shape =\", test_miRNA.shape)\n",
    "print(\"train_copy_number shape =\", train_copy_number.shape)\n",
    "print(\"val_copy_number shape =\", val_copy_number.shape)\n",
    "print(\"test_copy_number shape =\", test_copy_number.shape)\n",
    "print(\"train_y shape =\", train_y.shape)\n",
    "print(\"val_y shape =\", val_y.shape)\n",
    "print(\"test_y shape =\", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: 48034 samples\n",
      "Validation Dataset: 5338 samples\n",
      "Test Dataset: 5931 samples\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(train_smiles, train_expression, train_damaging_mutation, train_protein, train_hotspot_mutation, train_metabolomic, train_miRNA, train_copy_number, train_y)\n",
    "val_dataset = TensorDataset(val_smiles, val_expression, val_damaging_mutation, val_protein, val_hotspot_mutation, val_metabolomic, val_miRNA, val_copy_number, val_y)\n",
    "test_dataset = TensorDataset(test_smiles, test_expression, test_damaging_mutation, test_protein, test_hotspot_mutation, test_metabolomic, test_miRNA, test_copy_number, test_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train Dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Validation Dataset: {len(val_dataset)} samples\")\n",
    "print(f\"Test Dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual model\n",
    "##### !!!! should separate in other file, or just save the model itself (not only weight)\n",
    "class MultiTaskRegressionTransformer(nn.Module):\n",
    "    def __init__(self, chemberta_dim, d_model, nhead, num_layers, num_omics):\n",
    "        super(MultiTaskRegressionTransformer, self).__init__()\n",
    "        \n",
    "        # CLS expression for SMILES is already embedded seperately by ChemBERTa\n",
    "        self.chemberta_dim = chemberta_dim\n",
    "\n",
    "        # Omics -> Transformer Encoder\n",
    "        self.omics_fc = nn.Linear(num_omics, d_model)\n",
    "        self.omics_encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.omics_transformer = nn.TransformerEncoder(self.omics_encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # cls -> embed to d_model dimension\n",
    "        self.cls_proj = nn.Linear(self.chemberta_dim, d_model)\n",
    "        \n",
    "        # Cross-Attention (omics and drug data were embedded by different encoder, so we need to train their relationship additionally)\n",
    "        # SMILES -> omics\n",
    "        self.cross_attn_smiles = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)\n",
    "        # Omics -> SMILES\n",
    "        self.cross_attn_omics = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)\n",
    "        \n",
    "        # fuse two cross-attn information\n",
    "        self.fusion_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        \n",
    "        # prediction heads\n",
    "        self.ic50_head = nn.Linear(d_model, 1)\n",
    "        self.auc_head = nn.Linear(d_model, 1)\n",
    "        \n",
    "    def forward(self, cls_data, omics_data):\n",
    "        \"\"\"\n",
    "        cls_data: SMILES CLS expression (batch_size, chemberta_dim)\n",
    "        omics_data: (batch_size, num_omics) \n",
    "        \"\"\"\n",
    "        \n",
    "        # Omics: fc → Transformer Encoder\n",
    "        omics_repr = self.omics_fc(omics_data) # (batch_size, d_model)\n",
    "        omics_repr = omics_repr.unsqueeze(1) # (batch_size, 1, d_model)\n",
    "        omics_repr = self.omics_transformer(omics_repr) # (batch_size, 1, d_model)\n",
    "        omics_repr = omics_repr.squeeze(1) # (batch_size, d_model)\n",
    "        \n",
    "        # project SMILES to d_model\n",
    "        smiles_proj = self.cls_proj(cls_data) # (batch_size, d_model)\n",
    "        \n",
    "        # (batch_first=True → [batch, seq_len, d_model])\n",
    "        smiles_seq = smiles_proj.unsqueeze(1) # (batch_size, 1, d_model)\n",
    "        omics_seq = omics_repr.unsqueeze(1) # (batch_size, 1, d_model)\n",
    "        \n",
    "        # Cross-Attention\n",
    "        # 1. SMILES -> omics: query=smiles, key/value=omics\n",
    "        attn_smiles, _ = self.cross_attn_smiles(query=smiles_seq, key=omics_seq, value=omics_seq)\n",
    "        # 2. Omics -> SMILES: query=omics, key/value=smiles\n",
    "        attn_omics, _ = self.cross_attn_omics(query=omics_seq, key=smiles_seq, value=smiles_seq)\n",
    "        \n",
    "        # Residual connection (add attention result to original data) -> reserve original data\n",
    "        smiles_updated = smiles_proj + attn_smiles.squeeze(1) # (batch_size, d_model)\n",
    "        omics_updated = omics_repr + attn_omics.squeeze(1) # (batch_size, d_model)\n",
    "        \n",
    "        # Send to MLP\n",
    "        fused = torch.cat([smiles_updated, omics_updated], dim=1) # (batch_size, 2*d_model)\n",
    "        fused = self.fusion_mlp(fused) # (batch_size, d_model)\n",
    "        \n",
    "        # Final prediction\n",
    "        ic50_pred = self.ic50_head(fused) # (batch_size, 1)\n",
    "        auc_pred = self.auc_head(fused) # (batch_size, 1)\n",
    "        \n",
    "        return ic50_pred, auc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 정의 (저장할 때 사용한 클래스와 동일해야 함)\n",
    "#model = MultiTaskRegressionTransformer()  # YourModelClass()는 저장한 모델의 클래스\n",
    "\n",
    "# 모델 가중치 불러오기\n",
    "#model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "# 모델을 평가 모드로 전환 (추론 시 필요)\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_best_model_Expression_20250310_105831.pth', '2_best_model_Damaging_Mutations_20250310_042734.pth', '3_best_model_protein_20250310_065556.pth', '4_best_model_Hotspot_Mutations_20250310_014321.pth', '5_best_model_metabolomics_20250309_181849.pth', '6_best_model_miRNA_20250309_111221.pth', '7_best_model_CN_20250310_080710.pth']\n"
     ]
    }
   ],
   "source": [
    "# check name of models\n",
    "\"\"\"\n",
    "order: expression, damaging_mutation, protein_tensor, hotspot_mutation,\n",
    "metabolomic_tensor, miRNA, copy_number\n",
    "\n",
    "should keep the order in final_models folder!\n",
    "\"\"\"\n",
    "folder_path = './final_models'  # 폴더 경로 지정\n",
    "model_names = os.listdir(folder_path)\n",
    "\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512 # can be adjust, should be divisible by nhead\n",
    "nhead = 8 # can be adjust\n",
    "num_layers = 4 # can be adjust\n",
    "cls_dim = train_smiles.shape[1]\n",
    "omics_dimension_list = [train_expression.shape[1], train_damaging_mutation.shape[1], train_protein.shape[1], train_hotspot_mutation.shape[1], train_metabolomic.shape[1], train_miRNA.shape[1], train_copy_number.shape[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, model_paths):\n",
    "        \"\"\"\n",
    "        drug_input_dim: drug structure의 feature dimension (예: 100)\n",
    "        omics_dims: 각 omics 데이터의 feature dimension (예시)\n",
    "        \"\"\"\n",
    "        super(FinalModel, self).__init__()\n",
    "        \n",
    "        # call pretrained models, and freeze\n",
    "        self.pretrained_models = nn.ModuleList()\n",
    "        for i in range(7):\n",
    "            model = MultiTaskRegressionTransformer(cls_dim, d_model, nhead, num_layers, omics_dimension_list[i])\n",
    "            model_path = './final_models/' + model_paths[i]\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.pretrained_models.append(model)\n",
    "        \n",
    "        self.fc1 = nn.Linear(14, 64) # 2 * 7\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2) \n",
    "\n",
    "    def forward(self, drug_input, omics_inputs):\n",
    "        \"\"\"\n",
    "        drug_input: Tensor, shape (batch_size, drug_input_dim)\n",
    "        omics_inputs: list of 7 Tensors\n",
    "        \"\"\"\n",
    "        ic50_preds = []\n",
    "        auc_preds = []\n",
    "\n",
    "        # 7개의 모델에 각각 데이터 전달 -> (batch_size,)씩 나옴\n",
    "        for i, model in enumerate(self.pretrained_models):\n",
    "            ic50_pred, auc_pred = model(drug_input, omics_inputs[i]) # (batch_size,), (batch_size,)\n",
    "            \n",
    "            # 반드시 unsqueeze(1)을 사용해 (batch_size,) -> (batch_size, 1)로 변환\n",
    "            ic50_preds.append(ic50_pred.unsqueeze(1))\n",
    "            auc_preds.append(auc_pred.unsqueeze(1))\n",
    "            #print(ic50_preds.shape)\n",
    "\n",
    "        # (batch_size, 7)씩 나눠서 concat\n",
    "        ic50_preds = torch.cat(ic50_preds, dim=1) # (batch_size, 7)\n",
    "        auc_preds = torch.cat(auc_preds, dim=1)   # (batch_size, 7)\n",
    "        #print(ic50_preds.shape)\n",
    "\n",
    "        # 두 개의 예측값을 합쳐서 (batch_size, 14)로 변환\n",
    "        concat_preds = torch.cat([ic50_preds, auc_preds], dim=1) # (batch_size, 14)\n",
    "        concat_preds = concat_preds.squeeze(2)\n",
    "        #print(concat_preds.shape)\n",
    "        \n",
    "        # 최종 MLP를 거쳐서 최종 IC50/AUC 예측\n",
    "        x = F.relu(self.fc1(concat_preds))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        output = self.fc3(x) # (batch_size, 2)\n",
    "\n",
    "        return output[:, 0], output[:, 1] # (batch_size,), (batch_size,)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinalModel(model_names)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 - Train Loss: 0.0113 - Validation Loss: 0.0024\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 2/1000 - Train Loss: 0.0026 - Validation Loss: 0.0014\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 3/1000 - Train Loss: 0.0020 - Validation Loss: 0.0012\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 4/1000 - Train Loss: 0.0018 - Validation Loss: 0.0011\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 5/1000 - Train Loss: 0.0017 - Validation Loss: 0.0011\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 6/1000 - Train Loss: 0.0017 - Validation Loss: 0.0011\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 7/1000 - Train Loss: 0.0016 - Validation Loss: 0.0011\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 8/1000 - Train Loss: 0.0016 - Validation Loss: 0.0010\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 9/1000 - Train Loss: 0.0015 - Validation Loss: 0.0010\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 10/1000 - Train Loss: 0.0015 - Validation Loss: 0.0010\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 11/1000 - Train Loss: 0.0015 - Validation Loss: 0.0010\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 12/1000 - Train Loss: 0.0015 - Validation Loss: 0.0010\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 13/1000 - Train Loss: 0.0015 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 14/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 15/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 16/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 17/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 18/1000 - Train Loss: 0.0014 - Validation Loss: 0.0011\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 19/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 20/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 21/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 22/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 23/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 24/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 25/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 26/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 27/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 28/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 29/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 30/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 31/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 32/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 33/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 34/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 35/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 36/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 37/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 38/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 39/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 40/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 41/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 42/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 43/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 44/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 45/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 46/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 47/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 48/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 49/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 50/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 51/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 52/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 53/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 54/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 55/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 56/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 57/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 58/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 59/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 60/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 61/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 62/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 63/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 64/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 65/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 66/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 67/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 68/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 69/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 70/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 71/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 72/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 73/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 74/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 75/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 76/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 77/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 78/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 79/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch 80/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 81/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 82/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 83/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 84/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 85/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 86/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 87/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 88/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 89/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 90/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 91/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 92/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 93/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 94/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 95/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 96/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 97/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 98/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 99/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 100/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 101/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 102/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 103/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 104/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 105/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 106/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch 107/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 108/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 27 epoch(s).\n",
      "Epoch 109/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 28 epoch(s).\n",
      "Epoch 110/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 29 epoch(s).\n",
      "Epoch 111/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 30 epoch(s).\n",
      "Epoch 112/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 31 epoch(s).\n",
      "Epoch 113/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 32 epoch(s).\n",
      "Epoch 114/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 115/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 116/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 117/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 118/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 119/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 120/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 121/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 122/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 123/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 124/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 125/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 126/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 127/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 128/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 129/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 130/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 131/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 132/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 133/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 134/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 135/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 136/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 137/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 138/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 139/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 140/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 141/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 142/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 143/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 144/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 145/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 146/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 147/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 148/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 149/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 150/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 151/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 152/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 153/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 154/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 155/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 156/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 157/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 158/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 159/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 160/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 161/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 162/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 163/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 164/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch 165/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 166/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 27 epoch(s).\n",
      "Epoch 167/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 28 epoch(s).\n",
      "Epoch 168/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 29 epoch(s).\n",
      "Epoch 169/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 30 epoch(s).\n",
      "Epoch 170/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 31 epoch(s).\n",
      "Epoch 171/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 32 epoch(s).\n",
      "Epoch 172/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 33 epoch(s).\n",
      "Epoch 173/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 34 epoch(s).\n",
      "Epoch 174/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 35 epoch(s).\n",
      "Epoch 175/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 36 epoch(s).\n",
      "Epoch 176/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 37 epoch(s).\n",
      "Epoch 177/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 38 epoch(s).\n",
      "Epoch 178/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 39 epoch(s).\n",
      "Epoch 179/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 40 epoch(s).\n",
      "Epoch 180/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 181/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 182/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 183/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 184/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 185/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 186/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 187/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 188/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 189/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 190/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 191/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 192/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 193/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 194/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 195/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 196/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 197/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 198/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 199/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 200/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 201/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 202/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 203/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 204/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 205/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch 206/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 207/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 27 epoch(s).\n",
      "Epoch 208/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 28 epoch(s).\n",
      "Epoch 209/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 29 epoch(s).\n",
      "Epoch 210/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 30 epoch(s).\n",
      "Epoch 211/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 31 epoch(s).\n",
      "Epoch 212/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 32 epoch(s).\n",
      "Epoch 213/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 33 epoch(s).\n",
      "Epoch 214/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 34 epoch(s).\n",
      "Epoch 215/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 35 epoch(s).\n",
      "Epoch 216/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 36 epoch(s).\n",
      "Epoch 217/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 218/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 219/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 220/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 221/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 222/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 223/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 224/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 225/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 226/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 227/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 228/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 229/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 230/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 231/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 232/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 233/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 234/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 235/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 236/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 237/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 238/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 239/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 240/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 241/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 242/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch 243/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 244/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 27 epoch(s).\n",
      "Epoch 245/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 28 epoch(s).\n",
      "Epoch 246/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 247/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 248/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 249/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 250/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 251/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 252/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 253/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 254/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 255/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 256/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 257/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 258/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 259/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 260/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 261/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 262/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 263/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 264/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 265/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 266/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 267/1000 - Train Loss: 0.0014 - Validation Loss: 0.0010\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 268/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 269/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 270/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 271/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 272/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 273/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 274/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 275/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 276/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 277/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 278/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 279/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 280/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 281/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 282/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 283/1000 - Train Loss: 0.0013 - Validation Loss: 0.0010\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 284/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 285/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 286/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 287/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 288/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 289/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 290/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 291/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 292/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 293/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch 294/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 295/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 27 epoch(s).\n",
      "Epoch 296/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 28 epoch(s).\n",
      "Epoch 297/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 29 epoch(s).\n",
      "Epoch 298/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 30 epoch(s).\n",
      "Epoch 299/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 31 epoch(s).\n",
      "Epoch 300/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 32 epoch(s).\n",
      "Epoch 301/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 33 epoch(s).\n",
      "Epoch 302/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 34 epoch(s).\n",
      "Epoch 303/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 35 epoch(s).\n",
      "Epoch 304/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 36 epoch(s).\n",
      "Epoch 305/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 37 epoch(s).\n",
      "Epoch 306/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 38 epoch(s).\n",
      "Epoch 307/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 39 epoch(s).\n",
      "Epoch 308/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 40 epoch(s).\n",
      "Epoch 309/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 41 epoch(s).\n",
      "Epoch 310/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 42 epoch(s).\n",
      "Epoch 311/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 43 epoch(s).\n",
      "Epoch 312/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 44 epoch(s).\n",
      "Epoch 313/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 45 epoch(s).\n",
      "Epoch 314/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 46 epoch(s).\n",
      "Epoch 315/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 47 epoch(s).\n",
      "Epoch 316/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 48 epoch(s).\n",
      "Epoch 317/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 49 epoch(s).\n",
      "Epoch 318/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 50 epoch(s).\n",
      "Epoch 319/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 51 epoch(s).\n",
      "Epoch 320/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 52 epoch(s).\n",
      "Epoch 321/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 53 epoch(s).\n",
      "Epoch 322/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 54 epoch(s).\n",
      "Epoch 323/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 55 epoch(s).\n",
      "Epoch 324/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "Validation loss improved. Best model updated.\n",
      "Epoch 325/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 326/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 327/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 328/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 329/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 330/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 331/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 7 epoch(s).\n",
      "Epoch 332/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 8 epoch(s).\n",
      "Epoch 333/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 9 epoch(s).\n",
      "Epoch 334/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 10 epoch(s).\n",
      "Epoch 335/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 11 epoch(s).\n",
      "Epoch 336/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 12 epoch(s).\n",
      "Epoch 337/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 13 epoch(s).\n",
      "Epoch 338/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 14 epoch(s).\n",
      "Epoch 339/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 15 epoch(s).\n",
      "Epoch 340/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 16 epoch(s).\n",
      "Epoch 341/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 17 epoch(s).\n",
      "Epoch 342/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 18 epoch(s).\n",
      "Epoch 343/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 19 epoch(s).\n",
      "Epoch 344/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 20 epoch(s).\n",
      "Epoch 345/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 21 epoch(s).\n",
      "Epoch 346/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 22 epoch(s).\n",
      "Epoch 347/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 23 epoch(s).\n",
      "Epoch 348/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 24 epoch(s).\n",
      "Epoch 349/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 25 epoch(s).\n",
      "Epoch 350/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 26 epoch(s).\n",
      "Epoch 351/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 27 epoch(s).\n",
      "Epoch 352/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 28 epoch(s).\n",
      "Epoch 353/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 29 epoch(s).\n",
      "Epoch 354/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 30 epoch(s).\n",
      "Epoch 355/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 31 epoch(s).\n",
      "Epoch 356/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 32 epoch(s).\n",
      "Epoch 357/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 33 epoch(s).\n",
      "Epoch 358/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 34 epoch(s).\n",
      "Epoch 359/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 35 epoch(s).\n",
      "Epoch 360/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 36 epoch(s).\n",
      "Epoch 361/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 37 epoch(s).\n",
      "Epoch 362/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 38 epoch(s).\n",
      "Epoch 363/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 39 epoch(s).\n",
      "Epoch 364/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 40 epoch(s).\n",
      "Epoch 365/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 41 epoch(s).\n",
      "Epoch 366/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 42 epoch(s).\n",
      "Epoch 367/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 43 epoch(s).\n",
      "Epoch 368/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 44 epoch(s).\n",
      "Epoch 369/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 45 epoch(s).\n",
      "Epoch 370/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 46 epoch(s).\n",
      "Epoch 371/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 47 epoch(s).\n",
      "Epoch 372/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 48 epoch(s).\n",
      "Epoch 373/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 49 epoch(s).\n",
      "Epoch 374/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 50 epoch(s).\n",
      "Epoch 375/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 51 epoch(s).\n",
      "Epoch 376/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 52 epoch(s).\n",
      "Epoch 377/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 53 epoch(s).\n",
      "Epoch 378/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 54 epoch(s).\n",
      "Epoch 379/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 55 epoch(s).\n",
      "Epoch 380/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 56 epoch(s).\n",
      "Epoch 381/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 57 epoch(s).\n",
      "Epoch 382/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 58 epoch(s).\n",
      "Epoch 383/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 59 epoch(s).\n",
      "Epoch 384/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 60 epoch(s).\n",
      "Epoch 385/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 61 epoch(s).\n",
      "Epoch 386/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 62 epoch(s).\n",
      "Epoch 387/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 63 epoch(s).\n",
      "Epoch 388/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 64 epoch(s).\n",
      "Epoch 389/1000 - Train Loss: 0.0013 - Validation Loss: 0.0010\n",
      "No improvement for 65 epoch(s).\n",
      "Epoch 390/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 66 epoch(s).\n",
      "Epoch 391/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 67 epoch(s).\n",
      "Epoch 392/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 68 epoch(s).\n",
      "Epoch 393/1000 - Train Loss: 0.0013 - Validation Loss: 0.0010\n",
      "No improvement for 69 epoch(s).\n",
      "Epoch 394/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 70 epoch(s).\n",
      "Epoch 395/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 71 epoch(s).\n",
      "Epoch 396/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 72 epoch(s).\n",
      "Epoch 397/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 73 epoch(s).\n",
      "Epoch 398/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 74 epoch(s).\n",
      "Epoch 399/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 75 epoch(s).\n",
      "Epoch 400/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 76 epoch(s).\n",
      "Epoch 401/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 77 epoch(s).\n",
      "Epoch 402/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 78 epoch(s).\n",
      "Epoch 403/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 79 epoch(s).\n",
      "Epoch 404/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 80 epoch(s).\n",
      "Epoch 405/1000 - Train Loss: 0.0014 - Validation Loss: 0.0009\n",
      "No improvement for 81 epoch(s).\n",
      "Epoch 406/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 82 epoch(s).\n",
      "Epoch 407/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 83 epoch(s).\n",
      "Epoch 408/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 84 epoch(s).\n",
      "Epoch 409/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 85 epoch(s).\n",
      "Epoch 410/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 86 epoch(s).\n",
      "Epoch 411/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 87 epoch(s).\n",
      "Epoch 412/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 88 epoch(s).\n",
      "Epoch 413/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 89 epoch(s).\n",
      "Epoch 414/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 90 epoch(s).\n",
      "Epoch 415/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 91 epoch(s).\n",
      "Epoch 416/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 92 epoch(s).\n",
      "Epoch 417/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 93 epoch(s).\n",
      "Epoch 418/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 94 epoch(s).\n",
      "Epoch 419/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 95 epoch(s).\n",
      "Epoch 420/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 96 epoch(s).\n",
      "Epoch 421/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 97 epoch(s).\n",
      "Epoch 422/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 98 epoch(s).\n",
      "Epoch 423/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 99 epoch(s).\n",
      "Epoch 424/1000 - Train Loss: 0.0013 - Validation Loss: 0.0009\n",
      "No improvement for 100 epoch(s).\n",
      "Early stopping triggered!\n",
      "Best model saved to ./best_models/best_final_model_20250310_163355.pth\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "patience = 100 # for early stopping\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "best_model_filename = None\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        smiles_list, expression_data, damaging_mutation_data, protein_data, hotspot_mutation_data, metabolomic_data, miRNA_data, copy_number_data, targets = batch\n",
    "        omics_data = [expression_data, damaging_mutation_data, protein_data, hotspot_mutation_data, metabolomic_data, miRNA_data, copy_number_data]\n",
    "        ic50_targets, auc_targets = targets[:, 0], targets[:, 1]\n",
    "        \n",
    "        smiles_list = smiles_list.to(device)\n",
    "        omics_data = [data.to(device) for data in omics_data]\n",
    "        ic50_targets = ic50_targets.to(device)\n",
    "        auc_targets = auc_targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        ic50_pred, auc_pred = model(smiles_list, omics_data)\n",
    "\n",
    "        # weight for auc loss and IC50 loss\n",
    "        w_ic50 = 2.0 # AUC is trained easier than IC50, so set IC50 weight larger (need further experiment)\n",
    "        w_auc = 1.0   \n",
    "        loss = 0.0\n",
    "        \n",
    "        # compute loss for valid target (which is not NAN)\n",
    "        ic50_mask = ~torch.isnan(ic50_targets)\n",
    "        auc_mask = ~torch.isnan(auc_targets)\n",
    "        \n",
    "        if ic50_mask.sum() > 0:\n",
    "            loss_ic50 = criterion(ic50_pred[ic50_mask], ic50_targets[ic50_mask])\n",
    "            loss += w_ic50 * loss_ic50\n",
    "        if auc_mask.sum() > 0:\n",
    "            loss_auc = criterion(auc_pred[auc_mask], auc_targets[auc_mask])\n",
    "            loss += w_auc * loss_auc\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            smiles_list, expression_data, damaging_mutation_data, protein_data, hotspot_mutation_data, metabolomic_data, miRNA_data, copy_number_data, targets = batch\n",
    "            omics_data = [expression_data, damaging_mutation_data, protein_data, hotspot_mutation_data, metabolomic_data, miRNA_data, copy_number_data]\n",
    "            ic50_targets, auc_targets = targets[:, 0], targets[:, 1]\n",
    "            \n",
    "            smiles_list = smiles_list.to(device)\n",
    "            omics_data = [data.to(device) for data in omics_data]\n",
    "            ic50_targets = ic50_targets.to(device)\n",
    "            auc_targets = auc_targets.to(device)\n",
    "            \n",
    "            ic50_pred, auc_pred = model(smiles_list, omics_data)\n",
    "            \n",
    "            loss = 0.0\n",
    "            ic50_mask = ~torch.isnan(ic50_targets)\n",
    "            auc_mask = ~torch.isnan(auc_targets)\n",
    "            \n",
    "            if ic50_mask.sum() > 0:\n",
    "                loss_ic50 = criterion(ic50_pred[ic50_mask], ic50_targets[ic50_mask])\n",
    "                loss += loss_ic50\n",
    "            if auc_mask.sum() > 0:\n",
    "                loss_auc = criterion(auc_pred[auc_mask], auc_targets[auc_mask])\n",
    "                loss += loss_auc\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Train Loss: {avg_loss:.4f} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # best model saving & early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        best_model_state = model.state_dict() \n",
    "        best_model_filename = f\"./best_models/best_final_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth\"\n",
    "        print(\"Validation loss improved. Best model updated.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "    \n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "# save the best model\n",
    "if best_model_state is not None:\n",
    "    torch.save(best_model_state, best_model_filename)\n",
    "    print(f\"Best model saved to {best_model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Test Results:**\n",
      "IC50_MSE: 0.0007\n",
      "IC50_MAE: 0.0120\n",
      "IC50_R2: 0.9734\n",
      "AUC_MSE: 0.0004\n",
      "AUC_MAE: 0.0143\n",
      "AUC_R2: 0.9889\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# utility function for testing\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    ic50_preds, ic50_targets = [], []\n",
    "    auc_preds, auc_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            smiles_list, expression_data, damaging_mutation_data, protein_data, hotspot_mutation_data, metabolomic_data, miRNA_data, copy_number_data, targets = batch\n",
    "            omics_data = [expression_data, damaging_mutation_data, protein_data, hotspot_mutation_data, metabolomic_data, miRNA_data, copy_number_data]\n",
    "            ic50_true, auc_true = targets[:, 0], targets[:, 1]\n",
    "            \n",
    "            smiles_list = smiles_list.to(device)\n",
    "            omics_data = [data.to(device) for data in omics_data]\n",
    "            ic50_true = ic50_true.to(device)\n",
    "            auc_true = auc_true.to(device)\n",
    "\n",
    "            ic50_pred, auc_pred = model(smiles_list, omics_data)\n",
    "\n",
    "            ic50_mask = ~torch.isnan(ic50_true)\n",
    "            auc_mask = ~torch.isnan(auc_true)\n",
    "\n",
    "            if ic50_mask.sum() > 0:\n",
    "                ic50_preds.append(ic50_pred[ic50_mask].cpu().numpy())\n",
    "                ic50_targets.append(ic50_true[ic50_mask].cpu().numpy())\n",
    "            if auc_mask.sum() > 0:\n",
    "                auc_preds.append(auc_pred[auc_mask].cpu().numpy())\n",
    "                auc_targets.append(auc_true[auc_mask].cpu().numpy())\n",
    "\n",
    "        # list -> numpy\n",
    "        ic50_preds = np.concatenate(ic50_preds) if ic50_preds else np.array([])\n",
    "        ic50_targets = np.concatenate(ic50_targets) if ic50_targets else np.array([])\n",
    "        auc_preds = np.concatenate(auc_preds) if auc_preds else np.array([])\n",
    "        auc_targets = np.concatenate(auc_targets) if auc_targets else np.array([])\n",
    "\n",
    "        # evaluation\n",
    "        metrics = {}\n",
    "        if len(ic50_preds) > 0:\n",
    "            metrics[\"IC50_MSE\"] = mean_squared_error(ic50_targets, ic50_preds)\n",
    "            metrics[\"IC50_MAE\"] = mean_absolute_error(ic50_targets, ic50_preds)\n",
    "            metrics[\"IC50_R2\"] = r2_score(ic50_targets, ic50_preds)\n",
    "        if len(auc_preds) > 0:\n",
    "            metrics[\"AUC_MSE\"] = mean_squared_error(auc_targets, auc_preds)\n",
    "            metrics[\"AUC_MAE\"] = mean_absolute_error(auc_targets, auc_preds)\n",
    "            metrics[\"AUC_R2\"] = r2_score(auc_targets, auc_preds)\n",
    "\n",
    "        print(\"\\n **Test Results:**\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "        \n",
    "        # IC50 Scatter Plot\n",
    "        if len(ic50_preds) > 0:\n",
    "            plt.figure(figsize=(6,6))\n",
    "            plt.scatter(ic50_targets, ic50_preds, alpha=0.5, label=\"IC50 Predictions\")\n",
    "            # y = x \n",
    "            min_val = min(np.min(ic50_targets), np.min(ic50_preds))\n",
    "            max_val = max(np.max(ic50_targets), np.max(ic50_preds))\n",
    "            plt.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"y = x\")\n",
    "            plt.xlabel(\"IC50 Target\")\n",
    "            plt.ylabel(\"IC50 Prediction\")\n",
    "            plt.title(\"IC50 Scatter Plot\")\n",
    "            # R2\n",
    "            plt.text(0.05, 0.90, f\"R2 = {metrics['IC50_R2']:.4f}\", transform=plt.gca().transAxes, \n",
    "                     fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5))\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "        \n",
    "        # AUC Scatter Plot\n",
    "        if len(auc_preds) > 0:\n",
    "            plt.figure(figsize=(6,6))\n",
    "            plt.scatter(auc_targets, auc_preds, alpha=0.5, label=\"AUC Predictions\")\n",
    "            min_val = min(np.min(auc_targets), np.min(auc_preds))\n",
    "            max_val = max(np.max(auc_targets), np.max(auc_preds))\n",
    "            plt.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"y = x\")\n",
    "            plt.xlabel(\"AUC Target\")\n",
    "            plt.ylabel(\"AUC Prediction\")\n",
    "            plt.title(\"AUC Scatter Plot\")\n",
    "            plt.text(0.05, 0.90, f\"R2 = {metrics['AUC_R2']:.4f}\", transform=plt.gca().transAxes, \n",
    "                     fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5))\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# load the best model\n",
    "model.load_state_dict(torch.load(best_model_filename, map_location=device))\n",
    "\n",
    "# test\n",
    "test_metrics = test_model(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
